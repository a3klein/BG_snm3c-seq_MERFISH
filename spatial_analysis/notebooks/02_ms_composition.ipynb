{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely import Polygon, Point, box\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from adjustText import adjust_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41380bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = (4, 4)\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f4d6f",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337138ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_geometry(geometry_col):\n",
    "    \"\"\"\n",
    "    Randomly permute a GeoSeries of point geometries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geometry_col : geopandas.GeoSeries\n",
    "        A column of shapely Points (e.g., gdf.geometry).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoSeries\n",
    "        Shuffled GeoSeries (same geometries, new order).\n",
    "    \"\"\"\n",
    "    # Ensure input is a GeoSeries\n",
    "    if not isinstance(geometry_col, gpd.GeoSeries):\n",
    "        geometry_col = gpd.GeoSeries(geometry_col)\n",
    "\n",
    "    # Shuffle indices\n",
    "    shuffled = np.random.permutation(geometry_col)\n",
    "\n",
    "    return shuffled\n",
    "\n",
    "# functions from xingjiepan 2023 mouse atlas paper\n",
    "def adjust_p_value_matrix_by_BH(p_val_mtx):\n",
    "    '''Adjust the p-values in a matrix by the Benjamini/Hochberg method.\n",
    "    The matrix should be symmetric.\n",
    "    '''\n",
    "    p_val_sequential = []\n",
    "    N = p_val_mtx.shape[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            p_val_sequential.append(p_val_mtx[i, j])\n",
    "\n",
    "    p_val_sequential_bh = multipletests(p_val_sequential, method='fdr_bh')[1]\n",
    "    \n",
    "    adjusted_p_val_mtx = np.zeros((N, N))\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            adjusted_p_val_mtx[i, j] = p_val_sequential_bh[counter]\n",
    "            adjusted_p_val_mtx[j, i] = p_val_sequential_bh[counter]\n",
    "            counter += 1\n",
    "            \n",
    "    return adjusted_p_val_mtx\n",
    "\n",
    "def one_sided_pval(real, null_dist):\n",
    "    \"\"\"\n",
    "    Calculate one-sided p-value for real value against null distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    real : float\n",
    "        The observed real value.\n",
    "    null_dist : array-like\n",
    "        The null distribution values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        One-sided p-value.\n",
    "    \"\"\"\n",
    "    np.asarray(real)\n",
    "    null_dist = np.array(null_dist)\n",
    "    null_mean = np.mean(null_dist)\n",
    "    null_std = np.maximum(np.std(null_dist), 1e-6)\n",
    "    z_score = (real - null_mean) / null_std\n",
    "    p_vals = norm.sf(np.abs(z_score))\n",
    "    # adj_p_value = adjust_p_value_matrix_by_BH(p_vals)\n",
    "    adj_p_value = multipletests(p_vals, method='fdr_bh')[1]\n",
    "    # pval = (np.sum(null_dist >= real) + 1) / (len(null_dist) + 1)\n",
    "    return p_vals, adj_p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6efc0",
   "metadata": {},
   "source": [
    "### Functions for accumulating tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b98d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_tau2(yi, vi):\n",
    "    \"\"\"\n",
    "    DerSimonian–Laird estimator of between-study variance Tau sq.\n",
    "    \"\"\"\n",
    "    w = 1.0 / vi\n",
    "    ybar = np.sum(w * yi) / np.sum(w)\n",
    "    Q = np.sum(w * (yi - ybar) ** 2)\n",
    "    k = len(yi)\n",
    "    c = np.sum(w) - np.sum(w ** 2) / np.sum(w)\n",
    "    tau2 = max(0.0, (Q - (k - 1)) / c) if c > 0 else 0.0\n",
    "    return tau2, Q\n",
    "\n",
    "def re_meta(yi, vi):\n",
    "    \"\"\"\n",
    "    Run a random-effects meta-analysis given effect sizes yi and variances vi.\n",
    "    Returns pooled mean, SE, z-statistic, p-value, CI, tau-sq, and I-sq.\n",
    "    \"\"\"\n",
    "    tau2, Q = dl_tau2(yi, vi)\n",
    "    w_star = 1.0 / (vi + tau2)\n",
    "    mu = np.sum(w_star * yi) / np.sum(w_star)\n",
    "    se = np.sqrt(1.0 / np.sum(w_star))\n",
    "    z = mu / se if se > 0 else np.nan\n",
    "    p = 2 * norm.sf(abs(z)) if np.isfinite(z) else np.nan\n",
    "    ci_lb, ci_ub = mu - 1.96 * se, mu + 1.96 * se\n",
    "    k = len(yi)\n",
    "    I2 = max(0.0, (Q - (k - 1)) / Q) * 100 if (k > 1 and Q > 0) else 0.0\n",
    "    return dict(mu=mu, se=se, z=z, p=p,\n",
    "                ci_lb=ci_lb, ci_ub=ci_ub,\n",
    "                tau2=tau2, Q=Q, k=k, I2=I2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd2fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stacked_bar_chart(df, group_column, cell_type_column='cell_type', \n",
    "                           figsize=(12, 8), title=None, colors=None, \n",
    "                           show_percentages=True, rotation=45, rasterized=False,\n",
    "                           legend_threshold=5.0, text_threshold=2.0,\n",
    "                           legend_fontsize=12, def_fontsize=12, title_fontsize=12,\n",
    "                           xlabel=None, \n",
    "                        ):\n",
    "    \"\"\"\n",
    "    Create a stacked bar chart showing cell type percentages across groups.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataframe containing the data\n",
    "    group_column : str\n",
    "        Column name to group by (x-axis categories)\n",
    "    cell_type_column : str, default 'cell_type'\n",
    "        Column name containing cell type information\n",
    "    figsize : tuple, default (12, 8)\n",
    "        Figure size (width, height)\n",
    "    title : str, optional\n",
    "        Chart title\n",
    "    colors : list or dict, optional\n",
    "        Colors for cell types. If None, uses seaborn default palette\n",
    "    show_percentages : bool, default True\n",
    "        Whether to show percentage labels on bars\n",
    "    rotation : int, default 45\n",
    "        Rotation angle for x-axis labels\n",
    "    legend_threshold : float, default 5.0\n",
    "        Minimum percentage threshold for including cell types in legend\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig, ax : matplotlib figure and axis objects\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate cell type counts and percentages\n",
    "    counts = df.groupby([group_column, cell_type_column]).size().unstack(fill_value=0)\n",
    "    percentages = counts.div(counts.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    # Set up colors\n",
    "    n_cell_types = len(counts.columns)\n",
    "    if colors is None:\n",
    "        colors = sns.color_palette(\"Set3\", n_cell_types)\n",
    "    elif isinstance(colors, dict):\n",
    "        colors = [colors.get(ct, 'gray') for ct in counts.columns]\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Determine which cell types meet the legend threshold\n",
    "    # Calculate max percentage for each cell type across all groups\n",
    "    max_percentages = percentages.max(axis=0)\n",
    "    legend_cell_types = max_percentages[max_percentages >= legend_threshold].index.tolist()\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    bottom = np.zeros(len(percentages))\n",
    "    bars = []\n",
    "    \n",
    "    for i, cell_type in enumerate(percentages.columns):\n",
    "        # Only include in legend if it meets the threshold\n",
    "        label = cell_type if cell_type in legend_cell_types else None\n",
    "        \n",
    "        bar = ax.bar(percentages.index, percentages[cell_type], \n",
    "                    bottom=bottom, label=label, color=colors[i], \n",
    "                    rasterized=rasterized)\n",
    "        bars.append(bar)\n",
    "        \n",
    "        # Add percentage labels if requested\n",
    "        if show_percentages:\n",
    "            for j, (idx, value) in enumerate(percentages[cell_type].items()):\n",
    "                if value > text_threshold:  # Only show label if percentage > 2%\n",
    "                    ax.text(j, bottom[j] + value/2, f'{value:.1f}%', \n",
    "                           ha='center', va='center', fontsize=def_fontsize, fontweight='bold', \n",
    "                           rasterized=rasterized)\n",
    "        \n",
    "        bottom += percentages[cell_type]\n",
    "    \n",
    "    # Customize the plot\n",
    "    if xlabel is None: \n",
    "        ax.set_xlabel(group_column.replace('_', ' ').title(), fontsize=def_fontsize)\n",
    "    else: \n",
    "        ax.set_xlabel(xlabel, fontsize=def_fontsize)\n",
    "    ax.set_ylabel('Percentage (%)', fontsize=def_fontsize)\n",
    "    ax.set_ylim(0, 100)\n",
    "    \n",
    "    if title:\n",
    "        ax.set_title(title, fontsize=title_fontsize, fontweight='bold', rasterized=rasterized)\n",
    "    else:\n",
    "        ax.set_title(f'Cell Type Distribution by {group_column.replace(\"_\", \" \").title()}', \n",
    "                    fontsize=title_fontsize, fontweight='bold', rasterized=rasterized)\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    if rotation != 0: \n",
    "        plt.xticks(rotation=rotation, ha='right', fontsize=def_fontsize)\n",
    "    else: \n",
    "        plt.xticks(ha='center', fontsize=def_fontsize)\n",
    "    \n",
    "    # Add legend (only for cell types that meet the threshold)\n",
    "    legend_handles = [bar for bar, ct in zip(bars, percentages.columns) if ct in legend_cell_types]\n",
    "    if len(legend_handles) <= 20 and len(legend_handles) > 0:\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=legend_fontsize)\n",
    "    elif len(legend_handles) > 20:\n",
    "        # For many legend items, you might want to handle differently\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=legend_fontsize, ncol=2)\n",
    "    \n",
    "\n",
    "\n",
    "    # Add grid for better readability\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a dataframe 'df' with columns 'region' and 'cell_type'\n",
    "# fig, ax = create_stacked_bar_chart(df, group_column='region', cell_type_column='cell_type')\n",
    "# plt.show()\n",
    "\n",
    "# Alternative simpler version for quick use:\n",
    "def quick_stacked_bar(df, group_col, cell_type_col='cell_type'):\n",
    "    \"\"\"Quick version with minimal customization\"\"\"\n",
    "    counts = df.groupby([group_col, cell_type_col]).size().unstack(fill_value=0)\n",
    "    percentages = counts.div(counts.sum(axis=1), axis=0) * 100\n",
    "    \n",
    "    ax = percentages.plot(kind='bar', stacked=True, figsize=(10, 6), \n",
    "                         colormap='Set3', rot=45)\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.set_title(f'Cell Type Distribution by {group_col}')\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volcano(\n",
    "    df,\n",
    "    lfc_col=\"log_2FC\",\n",
    "    p_col=\"p_value\",\n",
    "    label_col=None,\n",
    "    alpha=0.05,\n",
    "    lfc_thresh=1.0,\n",
    "    top_labels=10,\n",
    "    title=\"Volcano Plot\",\n",
    "    figsize=(7,6),\n",
    "    ax=None,\n",
    "    save=None,\n",
    "    label_fontsize=8,\n",
    "    rasterized=False, \n",
    "):\n",
    "    \"\"\"\n",
    "    Volcano plot (log2FC vs -log10 p-value) using pure Matplotlib,\n",
    "    with adjustText-based non-overlapping labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing log2 fold change and p-values.\n",
    "    lfc_col : str\n",
    "        Column name for log2 fold change.\n",
    "    p_col : str\n",
    "        Column name for p-value.\n",
    "    label_col : str, optional\n",
    "        Column name for labeling points (e.g., cell type, interaction).\n",
    "    alpha : float\n",
    "        p-value threshold for significance.\n",
    "    lfc_thresh : float\n",
    "        Fold change threshold for significance.\n",
    "    top_labels : int\n",
    "        Number of most significant features to label.\n",
    "    title : str\n",
    "        Plot title.\n",
    "    figsize : tuple\n",
    "        Figure size.\n",
    "    ax : matplotlib.axes.Axes or None\n",
    "        Axis to plot on (creates new figure if None).\n",
    "    save : str or None\n",
    "        Path to save figure (if None, displays interactively).\n",
    "    label_fontsize : int\n",
    "        Font size for labels.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna(subset=[lfc_col, p_col])\n",
    "    df[\"neglog10p\"] = -np.log10(df[p_col].clip(lower=1e-300))  # avoid log(0)\n",
    "\n",
    "    # Classify points\n",
    "    sig_up = (df[p_col] < alpha) & (df[lfc_col] > lfc_thresh)\n",
    "    sig_down = (df[p_col] < alpha) & (df[lfc_col] < -lfc_thresh)\n",
    "    nonsig = ~(sig_up | sig_down)\n",
    "\n",
    "    # Create figure / axis\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # Scatter points\n",
    "    ax.scatter(\n",
    "        df.loc[nonsig, lfc_col],\n",
    "        df.loc[nonsig, \"neglog10p\"],\n",
    "        color=\"lightgray\", s=20, alpha=0.7, label=\"Not significant\",\n",
    "        rasterized=rasterized\n",
    "    )\n",
    "    ax.scatter(\n",
    "        df.loc[sig_up, lfc_col],\n",
    "        df.loc[sig_up, \"neglog10p\"],\n",
    "        color=\"red\", s=25, alpha=0.8, label=\"Up\",\n",
    "        rasterized=rasterized\n",
    "    )\n",
    "    ax.scatter(\n",
    "        df.loc[sig_down, lfc_col],\n",
    "        df.loc[sig_down, \"neglog10p\"],\n",
    "        color=\"blue\", s=25, alpha=0.8, label=\"Down\",\n",
    "        rasterized=rasterized\n",
    "    )\n",
    "\n",
    "    # Threshold lines\n",
    "    ax.axhline(-np.log10(alpha), color=\"black\", lw=1, ls=\"--\", rasterized=rasterized)\n",
    "    ax.axvline(lfc_thresh, color=\"black\", lw=1, ls=\"--\", rasterized=rasterized)\n",
    "    ax.axvline(-lfc_thresh, color=\"black\", lw=1, ls=\"--\", rasterized=rasterized)\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel(\"log2(Fold Change)\", fontsize=12)\n",
    "    ax.set_ylabel(\"−log10(p-value)\", fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.legend(frameon=False)\n",
    "\n",
    "    # --- Add non-overlapping labels ---\n",
    "    if label_col is not None and label_col in df.columns:\n",
    "        top = df.nsmallest(top_labels, p_col).copy()\n",
    "        texts = []\n",
    "        for _, row in top.iterrows():\n",
    "            txt = ax.text(\n",
    "                row[lfc_col],\n",
    "                row[\"neglog10p\"],\n",
    "                str(row[label_col]),\n",
    "                fontsize=label_fontsize,\n",
    "                color=\"black\",\n",
    "                weight=\"bold\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                rasterized=rasterized\n",
    "            )\n",
    "            texts.append(txt)\n",
    "\n",
    "        # Adjust text to prevent overlap\n",
    "        adjust_text(\n",
    "            texts,\n",
    "            ax=ax,\n",
    "            arrowprops=dict(arrowstyle=\"-\", color=\"gray\", lw=0.5)\n",
    "        )\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        fig.savefig(save, dpi=300, bbox_inches=\"tight\")\n",
    "        print(f\"Saved volcano plot to {save}\")\n",
    "    elif ax is None:  # Only show if not using external axes\n",
    "        plt.show()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68975bba",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77536c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/BICAN_BG_CPS.h5ad\"\n",
    "geom_store_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/regions/region_geometries_cps.parquet\"\n",
    "str_buffer = 25\n",
    "N_permute = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(ad_path)\n",
    "geoms = gpd.read_parquet(geom_store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580adc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = adata.obs['donor'].unique().tolist()\n",
    "replicates = adata.obs['replicate'].unique().tolist()\n",
    "brain_regions = adata.obs['brain_region'].unique().tolist()\n",
    "skip = [(\"UWA7648\", \"CAT\", \"ucsd\"), (\"UWA7648\", \"CAT\", \"salk\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bfbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = Path(\"/home/x-aklein2/projects/aklein/BICAN/BG/data/CPS/ms_enrichment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc1e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_donor = donors[1]\n",
    "_replicate = replicates[1]\n",
    "_region = brain_regions[4]\n",
    "print(f\"Processing donor: {_donor}, replicate: {_replicate}, region: {_region}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "_level = \"group\"\n",
    "_compartment = \"white_matter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = DIR / f\"ms_composition_{_level}_{_compartment}_{_donor}_{_region}_{_replicate}.csv\"\n",
    "ms_comp = pd.read_csv(input, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottnig a single Experiment: \n",
    "# fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
    "# for _i, _level in enumerate([\"subclass\", \"group\"]):\n",
    "#     for _j, _compartment in enumerate([\"white_matter\", \"matrix\", \"striosome\"]):\n",
    "#         ms_comp = pd.read_csv(\n",
    "#             DIR / f\"ms_composition_{_level}_{_compartment}_{_donor}_{_region}_{_replicate}.csv\",\n",
    "#             index_col=0\n",
    "#         )\n",
    "#         plot_volcano(ms_comp.reset_index(), p_col=\"p_value\", lfc_thresh=.1,\n",
    "#                      label_col=\"cell_type\", ax=axes[_i, _j], title=f\"{_level} - {_compartment}\",\n",
    "#                      top_labels=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba12719",
   "metadata": {},
   "outputs": [],
   "source": [
    "naming_map = {\n",
    "    \"subclass_white_matter\": \"Subclass - White Matter\",\n",
    "    \"subclass_matrix\": \"Subclass - Matrix\",\n",
    "    \"subclass_striosome\": \"Subclass - Striosome\",\n",
    "    \"group_white_matter\": \"Group - White Matter\",\n",
    "    \"group_matrix\": \"Group - Matrix\",\n",
    "    \"group_striosome\": \"Group - Striosome\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096dc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_tables = {}\n",
    "for _i, _level in enumerate([\"subclass\", \"group\"]):\n",
    "    for _j, _compartment in enumerate([\"white_matter\", \"matrix\", \"striosome\"]):\n",
    "        df_list = []\n",
    "        for _file in DIR.glob(f\"ms_composition_{_level}_{_compartment}*.csv\"):\n",
    "            _donor, _region, _lab = _file.stem.split(\"_\")[-3:]\n",
    "            df = pd.read_csv(_file)\n",
    "            df['donor'] = _donor\n",
    "            df['region'] = _region\n",
    "            df['lab'] = _lab\n",
    "            df['id'] = f\"{_donor}|{_region}|{_lab}\"\n",
    "            df_list.append(df)\n",
    "        df_ms = pd.concat(df_list, axis=0)\n",
    "\n",
    "        rows = []\n",
    "        for cat, df_cat in df_ms.groupby('cell_type'):\n",
    "            # df_cat['var_null'] = df_cat['std_null_count'] ** 2\n",
    "            res = re_meta(df_cat['log_2FC'].values, 1)\n",
    "            res['cell_type'] = cat\n",
    "            rows.append(res)\n",
    "        df_rows = pd.DataFrame(rows)\n",
    "        df_rows[\"p_fdr\"] = multipletests(df_rows[\"p\"], method=\"fdr_bh\")[1]\n",
    "        agg_tables[f\"{_level}_{_compartment}\"] = df_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_tables['group_striosome'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab196eb3",
   "metadata": {},
   "source": [
    "## MS - Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0198957",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/images/figures/supp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_palette(key): \n",
    "    if key.split(\"_\")[0] == \"subclass\": \n",
    "        return adata.uns['Subclass_palette']\n",
    "    # elif key.split(\"_\")[1] != \"white\": \n",
    "    #     return adata.uns['MSN_Groups_palette']\n",
    "    else: \n",
    "        return adata.uns['Group_palette']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
    "for i, (_key, df_ms) in enumerate(agg_tables.items()):\n",
    "    # print(f\"{_key}: {_value.shape}\")\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    palette = _get_palette(_key)\n",
    "\n",
    "    rightmost = max(df_ms['ci_ub'])\n",
    "    leftmost = min(df_ms['ci_lb'])\n",
    "    star_x = rightmost + (rightmost - leftmost) / 10\n",
    "    labels = []\n",
    "    for idx, (_c, _row) in enumerate(df_ms.sort_values(by=\"ci_lb\").iterrows()): \n",
    "        point = ax.scatter([_row['ci_lb'], _row['ci_ub']], [idx, idx], color=palette[_row['cell_type']])\n",
    "        ax.plot([_row['ci_lb'], _row['ci_ub']], [idx, idx], color=palette[_row['cell_type']])\n",
    "        labels.append(_row['cell_type'])\n",
    "        stars = \"\"\n",
    "        if _row['p_fdr'] < 0.01: \n",
    "            stars += \"*\"\n",
    "        if _row['p_fdr'] < 0.001: \n",
    "            stars += \"*\"\n",
    "        if _row['p_fdr'] < 0.0001: \n",
    "            stars += \"*\"\n",
    "        ax.text(star_x, idx-1, stars)\n",
    "        # print(stars)\n",
    "\n",
    "    ax.axvline(0, linestyle='--', color='gray', alpha=0.5)\n",
    "    ax.set_yticks(np.arange(0, len(labels)))\n",
    "    ax.set_yticklabels(labels, fontsize=6)\n",
    "    ax.grid(axis='y', linestyle='--', color='gray', alpha=0.25)\n",
    "    ax.set_title(naming_map[_key])\n",
    "plt.tight_layout()\n",
    "plt.savefig(image_path + \"/ms_enrichment_PI_all.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_enrichment_PI_all.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_enrichment_PI_all.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
    "for i, (_key, df_ms) in enumerate(agg_tables.items()):\n",
    "    # print(f\"{_key}: {_value.shape}\")\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    \n",
    "    plot_volcano(df_ms, p_col=\"p_fdr\", lfc_thresh=.1, lfc_col=\"mu\",\n",
    "                label_col=\"cell_type\", ax=ax, title=naming_map[_key],\n",
    "                top_labels=10, rasterized=True)\n",
    "# plt.savefig(image_path + \"/ms_enrichment_volcano_all.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(image_path + \"/ms_enrichment_volcano_all.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_enrichment_volcano_all.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f16119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_to_group_map = {}\n",
    "for _sub, _gr in adata.obs[['Subclass', 'Group']].drop_duplicates().groupby(\"Subclass\", observed=True):\n",
    "    subclass_to_group_map[_sub] = _gr['Group'].cat.remove_unused_categories().values\n",
    "    # break\n",
    "for _key, _value in subclass_to_group_map.items():\n",
    "    new_val = [v for v in _value if v != 'unknown']\n",
    "    subclass_to_group_map[_key] = new_val\n",
    "\n",
    "print(subclass_to_group_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific Regions: \n",
    "subclasses_to_investigate = ['CN ST18 GABA', 'CN VIP GABA', 'CN LAMP5-CXCL14 GABA', \"STR D1 MSN\", \"STR D2 MSN\", \"STR Hybrid MSN\"]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15,10))\n",
    "for i, (_key, df_ms) in enumerate(agg_tables.items()):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    if _key.startswith(\"group\"):\n",
    "        df_sub = df_ms[df_ms['cell_type'].isin(\n",
    "            list(itertools.chain.from_iterable(\n",
    "                subclass_to_group_map[_sub] for _sub in subclasses_to_investigate\n",
    "            )))]\n",
    "    else:\n",
    "        df_sub = df_ms[df_ms['cell_type'].isin(subclasses_to_investigate)]\n",
    "\n",
    "    plot_volcano(df_sub, p_col=\"p_fdr\", lfc_thresh=.1, lfc_col=\"mu\",\n",
    "                label_col=\"cell_type\", ax=ax, title=naming_map[_key],\n",
    "                top_labels=10)\n",
    "\n",
    "# plt.savefig(image_path + \"/ms_enrichment_volcano_sub.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(image_path + \"/ms_enrichment_volcano_sub.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_enrichment_volcano_sub.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_tables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Specific Regions: \n",
    "subclasses_to_investigate = ['CN ST18 GABA', 'CN VIP GABA', 'CN LAMP5-CXCL14 GABA']\n",
    "ncols = len(subclasses_to_investigate)\n",
    "nrows = 2\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(15,10))\n",
    "for c, _sub in enumerate(subclasses_to_investigate):\n",
    "    for i, (_key) in enumerate(['group_matrix', 'group_striosome']):\n",
    "        df_ms = agg_tables[_key]\n",
    "        ax = axes[i, c]\n",
    "        df_sub = df_ms[df_ms['cell_type'].isin(subclass_to_group_map[_sub])]\n",
    "        plot_volcano(df_sub, p_col=\"p_fdr\", lfc_thresh=.1, lfc_col=\"mu\",\n",
    "                    label_col=\"cell_type\", ax=ax, title=f\"{naming_map[_key]} - {_sub}\",\n",
    "                    top_labels=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.shape)\n",
    "adata = adata[adata.obs['neuron_type'] != \"unknown\"].copy()\n",
    "print(adata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wm = adata[adata.obs['wm_compartment'] == \"WM\"].obs.copy()\n",
    "df_mat = adata[adata.obs['MS_compartment'] == \"Matrix\"].obs.copy()\n",
    "df_str = adata[adata.obs['MS_compartment'] == \"Striosome\"].obs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99ce917",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_bar_chart(\n",
    "    df_wm,\n",
    "    group_column='brain_region_corr',\n",
    "    rotation=0,\n",
    "    cell_type_column='Group',\n",
    "    title='Cell Type Distribution in White Matter Regions',\n",
    "    colors=adata.uns['Group_palette'],\n",
    "    rasterized=True,\n",
    "    legend_threshold=2.0,\n",
    "    text_threshold=5.0,\n",
    "    legend_fontsize=14, \n",
    "    def_fontsize=14,\n",
    "    title_fontsize=24,\n",
    "    xlabel=\"\")\n",
    "# plt.savefig(image_path + \"/ms_composition_wm_group.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(image_path + \"/ms_composition_wm_group.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_composition_wm_group.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3951180",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_bar_chart(\n",
    "    df_wm,\n",
    "    group_column='brain_region_corr',\n",
    "    rotation=0,\n",
    "    cell_type_column='Subclass',\n",
    "    title='Cell Type Distribution in White Matter Regions',\n",
    "    colors=adata.uns['Subclass_palette'],\n",
    "    rasterized=True,\n",
    "    legend_threshold=2.0,\n",
    "    text_threshold=5.0,\n",
    "    legend_fontsize=14, \n",
    "    def_fontsize=14,\n",
    "    title_fontsize=24, \n",
    "    xlabel=\"\")\n",
    "# plt.savefig(image_path + \"/ms_composition_wm_subclass.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(image_path + \"/ms_composition_wm_subclass.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_composition_wm_subclass.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_bar_chart(\n",
    "    df_mat,\n",
    "    group_column='brain_region_corr',\n",
    "    rotation=0,\n",
    "    cell_type_column='MSN_Groups',\n",
    "    title='Cell Type Distribution in Matrix Regions',\n",
    "    colors=adata.uns['MSN_Groups_palette'],\n",
    "    rasterized=True,\n",
    "    legend_threshold=2.0,\n",
    "    text_threshold=5.0,\n",
    "    legend_fontsize=14, \n",
    "    def_fontsize=14,\n",
    "    title_fontsize=24,\n",
    "    xlabel=\"\")\n",
    "# plt.savefig(image_path + \"/ms_composition_matrix_subclass.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(image_path + \"/ms_composition_matrix_subclass.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_composition_matrix_subclass.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d600013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = create_stacked_bar_chart(\n",
    "    df_str,\n",
    "    group_column='brain_region_corr',\n",
    "    rotation=0,\n",
    "    cell_type_column='MSN_Groups',\n",
    "    title='Cell Type Distribution in Striosome Regions',\n",
    "    colors=adata.uns['MSN_Groups_palette'],\n",
    "    rasterized=True,\n",
    "    legend_threshold=2.0,\n",
    "    text_threshold=5.0,\n",
    "    legend_fontsize=14, \n",
    "    def_fontsize=14,\n",
    "    title_fontsize=24,\n",
    "    xlabel=\"\")\n",
    "# plt.savefig(image_path + \"/ms_composition_str_subclass.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(image_path + \"/ms_composition_str_subclass.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + \"/ms_composition_str_subclass.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6fa4ba",
   "metadata": {},
   "source": [
    "### Plotting the MS_NORM axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42891001",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_cells = gpd.GeoDataFrame(adata.obs, geometry=gpd.points_from_xy(adata.obs['CENTER_X'], adata.obs['CENTER_Y']), crs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf9b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (_donor, _region, _replicate) in enumerate(geoms.groupby(['donor', 'brain_region', 'lab']).groups):\n",
    "    sub_geoms = geoms[(geoms['donor'] == _donor) & \n",
    "                     (geoms['brain_region'] == _region) & \n",
    "                     (geoms['lab'] == _replicate)].copy()\n",
    "    sub_geoms.head()\n",
    "    if i == 34: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_geoms = geoms[(geoms['donor'] == _donor) & \n",
    "#                  (geoms['brain_region'] == _region) & \n",
    "#                  (geoms['lab'] == _replicate)].copy()\n",
    "# sub_geoms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sub_geoms[sub_geoms['type'] == \"White_Matter\"].plot(ax=ax, color='lightgray', edgecolor='black')\n",
    "sub_geoms[sub_geoms['type'] == \"Striosome\"].plot(ax=ax, color='red', edgecolor='black', alpha=0.5)\n",
    "sub_geoms[sub_geoms['type'] == \"Matrix\"].plot(ax=ax, color='blue', edgecolor='black', alpha=0.5)\n",
    "# int_geoms.plot(ax=ax, color='purple', edgecolor='black', alpha=0.7)\n",
    "ax.set_title(f\"{_donor} {_region} {_replicate}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = gdf_cells[(gdf_cells['donor'] == _donor) & \n",
    "                  (gdf_cells['brain_region'] == _region) & \n",
    "                  (gdf_cells['replicate'] == _replicate)].copy()\n",
    "_region_corr = cells['brain_region_corr'].unique()[0]\n",
    "# cells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.plot(ax=ax, column=\"Group\", markersize=1, color=gdf['group_color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells['group_color'] = cells['Group'].map(adata.uns['Group_palette'])\n",
    "cells['subclass_color'] = cells['Subclass'].map(adata.uns['Subclass_palette'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539f9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=300)\n",
    "norm = TwoSlopeNorm(vmin=cells['MS_NORM'].min(), vcenter=0, vmax=cells['MS_NORM'].max())\n",
    "cells.plot(ax=ax, color=\"gray\", edgecolor='none', markersize=2, alpha=0.5, rasterized=True);\n",
    "cells.plot(ax=ax, column=\"MS_NORM\", cmap='coolwarm_r', edgecolor='none', markersize=2, alpha=0.75, legend_kwds={\"label\" : \"Mat-Str Score\", \"shrink\":.6}, norm=norm, legend=True, rasterized=True).axis(\"off\");\n",
    "cbar_ax = fig.axes[1]\n",
    "ax.set_title(f\"{_region_corr} - {_donor}\")\n",
    "plt.savefig(image_path + f\"/ms_score_{_donor}_{_region}_{_replicate}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_score_{_donor}_{_region}_{_replicate}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_score_{_donor}_{_region}_{_replicate}.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cells.plot(ax=ax, color=cells['group_color'], edgecolor='none', markersize=1, alpha=1, rasterized=True).axis(\"off\");\n",
    "ax.set_title(f\"{_region_corr} - {_donor}\")\n",
    "plt.savefig(image_path + f\"/ms_group_{_donor}_{_region}_{_replicate}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_group_{_donor}_{_region}_{_replicate}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_group_{_donor}_{_region}_{_replicate}.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cells.plot(ax=ax, color=cells['subclass_color'], edgecolor='none', markersize=1, alpha=1, rasterized=True).axis(\"off\");\n",
    "ax.set_title(f\"{_region_corr} - {_donor}\")\n",
    "plt.savefig(image_path + f\"/ms_subclass_{_donor}_{_region}_{_replicate}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_subclass_{_donor}_{_region}_{_replicate}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_subclass_{_donor}_{_region}_{_replicate}.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "gdf_msn = cells.loc[~cells['MSN_Groups'].isna()]\n",
    "gdf_msn['group_color'] = gdf_msn['MSN_Groups'].map(adata.uns['MSN_Groups_palette']).fillna(\"gray\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "gdf_msn.plot(ax=ax, color=gdf_msn['group_color'], edgecolor='none', markersize=2, alpha=1, rasterized=True).axis(\"off\");\n",
    "sub_geoms[sub_geoms['type'] == \"White_Matter\"].plot(ax=ax, color='none', edgecolor='black', alpha=1, linewidth=0.5)\n",
    "sub_geoms[sub_geoms['type'] == \"Striosome\"].plot(ax=ax, color='none', edgecolor='black', alpha=1, linewidth=0.5)\n",
    "sub_geoms[sub_geoms['type'] == \"Matrix\"].plot(ax=ax, color='none', edgecolor='black', alpha=1, linewidth=0.5)\n",
    "ax.set_title(f\"{_region_corr} - {_donor}\")\n",
    "plt.savefig(image_path + f\"/ms_msn_group_{_donor}_{_region}_{_replicate}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_msn_group_{_donor}_{_region}_{_replicate}.pdf\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(image_path + f\"/ms_msn_group_{_donor}_{_region}_{_replicate}.svg\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()\n",
    "plt.close()\n",
    "\n",
    "# cbar_ax.set_yticks([-400, -200, 0, 500, 1000, 1500])\n",
    "# cbar_ax.set_yticklabels(['-400', '-200', '0', '500', '1000', '1500'])\n",
    "# cbar_ax.tick_params(labelsize=12)\n",
    "\n",
    "# sub_geoms[sub_geoms['type'] == \"White_Matter\"].plot(ax=ax, color=sub_geoms['type_color'], edgecolor='none', alpha=0.1)\n",
    "# sub_geoms[sub_geoms['type'] == \"White_Matter\"].plot(ax=ax, color='none', edgecolor='black', alpha=1, linewidth=0.5)\n",
    "\n",
    "# sub_geoms[sub_geoms['type'] == \"Striosome\"].plot(ax=ax, color=sub_geoms['type_color'], edgecolor='none', alpha=0.5)\n",
    "# sub_geoms[sub_geoms['type'] == \"Striosome\"].plot(ax=ax, color='none', edgecolor='black', alpha=1, linewidth=0.5)\n",
    "\n",
    "# sub_geoms[sub_geoms['type'] == \"Matrix\"].plot(ax=ax, color=sub_geoms['type_color'], edgecolor='none', alpha=0.5)\n",
    "# sub_geoms[sub_geoms['type'] == \"Matrix\"].plot(ax=ax, color='none', edgecolor='black', alpha=1, linewidth=0.5)\n",
    "\n",
    "# sub_geoms[sub_geoms['type'] == \"Striosome\"].plot(ax=ax, color='red', edgecolor='black', alpha=0.1)\n",
    "# sub_geoms[sub_geoms['type'] == \"Matrix\"].plot(ax=ax, color='blue', edgecolor='black', alpha=0.1)\n",
    "\n",
    "# str_geoms.plot(ax=ax, color='red', edgecolor='none', alpha=0.05)\n",
    "# mat_geoms.plot(ax=ax, color='blue', edgecolor='none', alpha=0.05)\n",
    "# str_geoms.plot(ax=ax, color='none', edgecolor='black', linewidth=1, alpha=1)\n",
    "# mat_geoms.plot(ax=ax, color='none', edgecolor='black', linewidth=1, alpha=1)\n",
    "\n",
    "# ax.legend()\n",
    "# ax.set_title(f\"{_donor} {_region} {_replicate}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba303019",
   "metadata": {},
   "source": [
    "## Functions for accumulating tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c0175f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a33732",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_rows = []\n",
    "for pair, dfg in df.groupby(\"pair\"):\n",
    "    for region, dfr in dfg.groupby(\"brain_region\"):\n",
    "        # Need ≥2 experiments to estimate heterogeneity\n",
    "        if len(dfr) >= 2:\n",
    "            res = re_meta(dfr[\"yi\"].values, dfr[\"vi\"].values)\n",
    "            res.update(pair=pair, brain_region=region)\n",
    "            region_rows.append(res)\n",
    "\n",
    "per_region = pd.DataFrame(region_rows)\n",
    "if len(per_region):\n",
    "    # Benjamini–Hochberg FDR correction within all tests\n",
    "    per_region[\"p_fdr\"] = sm.stats.multipletests(per_region[\"p\"], method=\"fdr_bh\")[1]\n",
    "    per_region.to_csv(DIR / \"meta_region_pooled.csv\", index=False)\n",
    "print(\"Wrote meta_region_pooled.csv (pooled z per pair × region)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ea42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_squared(effect_sizes, weights):\n",
    "    k = len(effect_sizes)\n",
    "    if k <= 1:\n",
    "        return np.nan\n",
    "    mean_eff = np.average(effect_sizes, weights=weights)\n",
    "    Q = np.sum(weights * (effect_sizes - mean_eff) ** 2)\n",
    "    df = k - 1\n",
    "    return max(0, (Q - df) / Q) * 100 if Q > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8342913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Simulate data: 8 regions × 4 donors × 2 reps\n",
    "#    True variance components (you can change these):\n",
    "# ------------------------------------------------------------\n",
    "R   = 8\n",
    "D   = 4\n",
    "REP = 2\n",
    "regions = [f\"R{i+1}\" for i in range(R)]\n",
    "donors  = [f\"D{j+1}\" for j in range(D)]\n",
    "\n",
    "# True means per region (arbitrary)\n",
    "mu_region = {r: rng.normal(loc=0.0, scale=0.5) for r in regions}\n",
    "\n",
    "# True variance components\n",
    "tau2_donor_true = 0.15   # donor heterogeneity\n",
    "tau2_rep_true   = 0.05   # replicate heterogeneity\n",
    "sigma2_within   = 1.0    # z-scale residual variance\n",
    "\n",
    "rows = []\n",
    "for r in regions:\n",
    "    for d in donors:\n",
    "        donor_uid = f\"{r}:{d}\"      # make donors unique per region\n",
    "        b_donor = rng.normal(0, np.sqrt(tau2_donor_true))\n",
    "        for rep in range(1, REP+1):\n",
    "            study_id = f\"{donor_uid}:rep{rep}\"\n",
    "            b_rep   = rng.normal(0, np.sqrt(tau2_rep_true))\n",
    "            # one \"study\" (effect estimate) per replicate\n",
    "            y = mu_region[r] + b_donor + b_rep + rng.normal(0, np.sqrt(sigma2_within))\n",
    "            rows.append({\"region\": r, \"donor_uid\": donor_uid, \"study_id\": study_id, \"yi\": y})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Fit pooled REML mixed model:\n",
    "#    yi ~ C(region) + (1 | donor_uid) + (1 | study_id)\n",
    "#    In statsmodels: donor as groups, study_id via vc_formula\n",
    "# ------------------------------------------------------------\n",
    "# Make sure grouping variables are strings/categoricals\n",
    "df[\"region\"]    = df[\"region\"].astype(str)\n",
    "df[\"donor_uid\"] = df[\"donor_uid\"].astype(str)\n",
    "df[\"study_id\"]  = df[\"study_id\"].astype(str)\n",
    "df[\"yi\"]        = df[\"yi\"].astype(float)\n",
    "\n",
    "# MixedLM via formula interface to allow vc_formula\n",
    "model = sm.MixedLM.from_formula(\n",
    "    \"yi ~ C(region)\",\n",
    "    groups=\"donor_uid\",\n",
    "    vc_formula={\"rep\": \"0 + C(study_id)\"},\n",
    "    data=df\n",
    ")\n",
    "\n",
    "fit = model.fit(reml=True, method=\"lbfgs\", maxiter=1000, disp=False)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Extract variance components robustly across versions\n",
    "# ------------------------------------------------------------\n",
    "# donor variance:\n",
    "if hasattr(fit, \"cov_re\") and getattr(fit.cov_re, \"shape\", (0,0))[0] > 0:\n",
    "    tau2_donor_hat = float(fit.cov_re.iloc[0, 0])\n",
    "else:\n",
    "    tau2_donor_hat = 0.0  # boundary solution\n",
    "\n",
    "# replicate variance (vc component); fit.vcomp can be array/Series/float\n",
    "tau2_rep_hat = 0.0\n",
    "if hasattr(fit, \"vcomp\"):\n",
    "    v = fit.vcomp\n",
    "    if isinstance(v, (float, int, np.floating)):\n",
    "        tau2_rep_hat = float(v)\n",
    "    elif hasattr(v, \"__len__\") and len(v) > 0:\n",
    "        tau2_rep_hat = float(v[0])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Convert to I^2 on the z-scale\n",
    "# ------------------------------------------------------------\n",
    "I2_donor = 100.0 * tau2_donor_hat / (tau2_donor_hat + sigma2_within)\n",
    "I2_rep   = 100.0 * tau2_rep_hat   / (tau2_rep_hat   + sigma2_within)\n",
    "\n",
    "print(\"=== REML pooled across regions ===\")\n",
    "print(f\"tau^2_donor (true {tau2_donor_true:.3f})  = {tau2_donor_hat:.3f}  → I^2_donor = {I2_donor:.1f}%\")\n",
    "print(f\"tau^2_rep   (true {tau2_rep_true:.3f})    = {tau2_rep_hat:.3f}    → I^2_rep   = {I2_rep:.1f}%\")\n",
    "\n",
    "# Optional: view fixed effects (region means)\n",
    "print(\"\\nFixed effects (region means, relative to reference):\")\n",
    "print(fit.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _aggregate_tests(DIR, file_format, ): \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c85d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a65064e",
   "metadata": {},
   "source": [
    "## MS ENRICHMENT CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here on this needs to be iterable. \n",
    "# contact_list = []\n",
    "pbar = tqdm(itertools.product(donors, brain_regions, replicates))\n",
    "for _i in pbar:\n",
    "    if _i in skip:\n",
    "        # print(f\"Skipping {_i}\")\n",
    "        continue\n",
    "    _donor, _brain_region, _replicate, = _i\n",
    "    pbar.set_description(f\"Processing {_donor} | {_brain_region} | {_replicate}\")\n",
    "    adata_sub = adata[ (adata.obs['donor'] == _donor) & \n",
    "                       (adata.obs['brain_region'] == _brain_region) & \n",
    "                       (adata.obs['replicate'] == _replicate) ].copy()\n",
    "    geoms_sub = geoms[ (geoms['donor'] == _donor) & \n",
    "                       (geoms['brain_region'] == _brain_region) & \n",
    "                       (geoms['lab'] == _replicate) ].copy()\n",
    "    if geoms_sub.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(adata_sub.obs, geometry=gpd.points_from_xy(adata_sub.obs['CENTER_X'], adata_sub.obs['CENTER_Y']), crs=None)\n",
    "\n",
    "    subclass_cells = gdf['Subclass'].unique().tolist()\n",
    "    group_cells = gdf['Group'].unique().tolist()\n",
    "\n",
    "    mat_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Matrix'], how=\"inner\", predicate='within')\n",
    "    mat_cells = mat_cells.loc[~mat_cells.index.duplicated(keep=\"first\")]\n",
    "    str_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Striosome'], how=\"inner\", predicate='within')\n",
    "    str_cells = str_cells.loc[~str_cells.index.duplicated(keep=\"first\")]\n",
    "    wm_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'White_Matter'], how=\"inner\", predicate='within')\n",
    "    wm_cells = wm_cells.loc[~wm_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    sub_mat_counts = mat_cells.groupby(\"Subclass\", observed=False).size().to_dict()\n",
    "    sub_str_counts = str_cells.groupby(\"Subclass\", observed=False).size().to_dict()\n",
    "    sub_wm_counts = wm_cells.groupby(\"Subclass\", observed=False).size().to_dict()\n",
    "\n",
    "    gr_mat_counts = mat_cells.groupby(\"Group\", observed=False).size().to_dict()\n",
    "    gr_str_counts = str_cells.groupby(\"Group\", observed=False).size().to_dict()\n",
    "    gr_wm_counts = wm_cells.groupby(\"Group\", observed=False).size().to_dict()\n",
    "\n",
    "    null_sub_mat_counts = {a: [] for a in subclass_cells}\n",
    "    null_sub_str_counts = {a: [] for a in subclass_cells}\n",
    "    null_sub_wm_counts = {a: [] for a in subclass_cells}\n",
    "    null_gr_mat_counts = {a: [] for a in group_cells}\n",
    "    null_gr_str_counts = {a: [] for a in group_cells}\n",
    "    null_gr_wm_counts = {a: [] for a in group_cells}\n",
    "\n",
    "    for i in range(N_permute): \n",
    "        gdf.geometry = permute_geometry(gdf.geometry)\n",
    "\n",
    "        mat_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Matrix'], how=\"inner\", predicate='within')\n",
    "        mat_cells = mat_cells.loc[~mat_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        str_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Striosome'], how=\"inner\", predicate='within')\n",
    "        str_cells = str_cells.loc[~str_cells.index.duplicated(keep=\"first\")]\n",
    "        \n",
    "        wm_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'White_Matter'], how=\"inner\", predicate='within')\n",
    "        wm_cells = wm_cells.loc[~wm_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        \n",
    "        for a, b in mat_cells.groupby(\"Subclass\", observed=False).size().items(): \n",
    "            null_sub_mat_counts[a].append(b)\n",
    "        \n",
    "        for a, b in str_cells.groupby(\"Subclass\", observed=False).size().items(): \n",
    "            null_sub_str_counts[a].append(b)\n",
    "        \n",
    "        for a, b in wm_cells.groupby(\"Subclass\", observed=False).size().items(): \n",
    "            null_sub_wm_counts[a].append(b)\n",
    "\n",
    "        for a, b in mat_cells.groupby(\"Group\", observed=False).size().items(): \n",
    "            null_gr_mat_counts[a].append(b)\n",
    "        \n",
    "        for a, b in str_cells.groupby(\"Group\", observed=False).size().items(): \n",
    "            null_gr_str_counts[a].append(b)\n",
    "        \n",
    "        for a, b in wm_cells.groupby(\"Group\", observed=False).size().items(): \n",
    "            null_gr_wm_counts[a].append(b)\n",
    "\n",
    "    naming = [\"subclass_matrix\", \"subclass_striosome\", \"subclass_white_matter\",\n",
    "            \"group_matrix\", \"group_striosome\", \"group_white_matter\"]\n",
    "    real_dicts = [sub_mat_counts, sub_str_counts, sub_wm_counts,\n",
    "                gr_mat_counts, gr_str_counts, gr_wm_counts]\n",
    "    null_dicts = [null_sub_mat_counts, null_sub_str_counts, null_sub_wm_counts,\n",
    "                null_gr_mat_counts, null_gr_str_counts, null_gr_wm_counts]\n",
    "\n",
    "    for i, (_name, _real, _null) in enumerate(zip(naming, real_dicts, null_dicts)):\n",
    "        ps, adj_ps = one_sided_pval(list(_real.values()), list(_null.values()))\n",
    "        cell_types = _real.keys()\n",
    "        result_df = pd.DataFrame({\n",
    "            \"cell_type\": cell_types,\n",
    "            \"real_count\": [_real[ct] for ct in cell_types],\n",
    "            \"mean_null_count\": [np.mean(_null[ct]) for ct in cell_types],\n",
    "            \"std_null_count\": [np.std(_null[ct]) for ct in cell_types],\n",
    "            \"p_value\": ps,\n",
    "            \"adj_p_value\": adj_ps,\n",
    "            \"log_2FC\": [np.log2( (_real[ct] + 1) / (np.mean(_null[ct]) + 1) ) for ct in cell_types]\n",
    "        })\n",
    "        # output_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/spatial_analysis/results/ms_composition/\"\n",
    "        # os.makedirs(output_path, exist_ok=True)\n",
    "        # result_df.to_csv(Path(output_path) / f\"ms_composition_{_name}_{_donor}_{_brain_region}_{_replicate}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc68a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_area = geoms_sub[geoms_sub['type'] == \"Striosome\"].geometry.area.sum()\n",
    "mtr_area = geoms_sub[geoms_sub['type'] == \"Matrix\"].geometry.area.sum()\n",
    "print(f\"Total striosome area: {str_area:.2f}, total matrix area: {mtr_area:.2f}\")\n",
    "# adata_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = sub_mat_counts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f608ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = one_sided_pval(list(sub_mat_counts.values()), list(null_sub_mat_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186d04b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeeefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6cc92d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7730a12c",
   "metadata": {},
   "source": [
    "### OLD WM INTEGRATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb08592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4546bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geoms_colors = {\n",
    "#     \"White_Matter\": \"lightgray\",\n",
    "#     \"Striosome\": \"red\",\n",
    "#     \"Matrix\": \"blue\"\n",
    "# }\n",
    "# geoms['type_color'] = geoms['type'].map(geoms_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d244e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _combine_ms_wm(geoms): \n",
    "\n",
    "#     new_geoms = geoms.copy()\n",
    "#     str_geoms = geoms[geoms['type'] == \"Striosome\"].copy()\n",
    "#     new_geoms.geometry = new_geoms.geometry.difference(str_geoms.unary_union.buffer(str_buffer))\n",
    "#     new_geoms.loc[str_geoms.index, str_geoms.columns] = str_geoms\n",
    "#     mat_geoms = new_geoms[new_geoms['type'] == \"Matrix\"].copy()\n",
    "#     wm_geoms = new_geoms[new_geoms['type'] == \"White_Matter\"].copy()\n",
    "\n",
    "#     wm_geoms['wm_id'] = range(len(wm_geoms))\n",
    "#     mat_geoms['mat_id'] = range(len(mat_geoms))\n",
    "#     str_geoms['str_id'] = range(len(str_geoms))\n",
    "\n",
    "#     ints = gpd.overlay(mat_geoms, wm_geoms, how='intersection')\n",
    "#     ints['mat_area'] = ints['mat_id'].apply(lambda x: mat_geoms.loc[mat_geoms['mat_id'] == x, 'geometry'].values[0].area)\n",
    "#     ints['wm_area'] = ints['wm_id'].apply(lambda x: wm_geoms.loc[wm_geoms['wm_id'] == x, 'geometry'].values[0].area)\n",
    "\n",
    "#     # Remove overlapping regions\n",
    "#     new_geoms.geometry = new_geoms.geometry.difference(ints.geometry.unary_union.buffer(str_buffer))\n",
    "\n",
    "#     new_ints = []\n",
    "#     for index, row in ints.iterrows(): \n",
    "#         if row['mat_area'] < row['wm_area']:\n",
    "#             keep = \"1\"\n",
    "#             keep_idx = row['mat_id']\n",
    "#         else: \n",
    "#             keep = \"2\"\n",
    "#             keep_idx = row['wm_id']\n",
    "#         keep_row = [keep_idx]\n",
    "#         for _col in geoms.columns: \n",
    "#             if _col == \"geometry\": \n",
    "#                 keep_row.append(row['geometry'])\n",
    "#             else: \n",
    "#                 keep_row.append(row[f\"{_col}_{keep}\"])\n",
    "#         new_ints.append(keep_row)\n",
    "#     add_ints = gpd.GeoDataFrame(new_ints, columns=[\"keep_idx\"] + list(geoms.columns))\n",
    "\n",
    "#     new_geoms = pd.concat([new_geoms, add_ints.drop(columns=[\"keep_idx\"])])\n",
    "#     new_geoms = new_geoms.loc[~new_geoms.is_empty]\n",
    "#     return new_geoms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b3e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # From here on this needs to be iterable. \n",
    "# contact_list = []\n",
    "# pbar = tqdm(itertools.product(donors, brain_regions, replicates))\n",
    "# for _i in pbar:\n",
    "#     if _i in skip:\n",
    "#         # print(f\"Skipping {_i}\")\n",
    "#         continue\n",
    "#     _donor, _brain_region, _replicate, = _i\n",
    "#     pbar.set_description(f\"Processing {_donor} | {_brain_region} | {_replicate}\")\n",
    "    \n",
    "#     ### combine\n",
    "#     sub_geoms = geoms[(geoms['brain_region'] == _brain_region) & (geoms['lab'] == _replicate) & (geoms['donor'] == _donor)]\n",
    "#     fig, ax = plt.subplots(figsize=(5,5))\n",
    "#     sub_geoms.plot(ax=ax, color=sub_geoms['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "#     sub_geoms.plot(ax=ax, color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "#     plt.show()\n",
    "\n",
    "#     new_geoms = _combine_ms_wm(sub_geoms)\n",
    "\n",
    "#     # new_geoms = sub_geoms.copy()\n",
    "#     # str_geoms = sub_geoms[sub_geoms['type'] == \"Striosome\"].copy()\n",
    "#     # new_geoms.geometry = new_geoms.geometry.difference(str_geoms.unary_union.buffer(str_buffer))\n",
    "#     # new_geoms.loc[str_geoms.index, str_geoms.columns] = str_geoms\n",
    "#     # mat_geoms = new_geoms[new_geoms['type'] == \"Matrix\"].copy()\n",
    "#     # wm_geoms = new_geoms[new_geoms['type'] == \"White_Matter\"].copy()\n",
    "\n",
    "#     # wm_geoms['wm_id'] = range(len(wm_geoms))\n",
    "#     # mat_geoms['mat_id'] = range(len(mat_geoms))\n",
    "#     # str_geoms['str_id'] = range(len(str_geoms))\n",
    "\n",
    "#     # ints = gpd.overlay(mat_geoms, wm_geoms, how='intersection')\n",
    "#     # ints['mat_area'] = ints['mat_id'].apply(lambda x: mat_geoms.loc[mat_geoms['mat_id'] == x, 'geometry'].values[0].area)\n",
    "#     # ints['wm_area'] = ints['wm_id'].apply(lambda x: wm_geoms.loc[wm_geoms['wm_id'] == x, 'geometry'].values[0].area)\n",
    "\n",
    "#     # # Remove overlapping regions\n",
    "#     # new_geoms.geometry = new_geoms.geometry.difference(ints.geometry.unary_union.buffer(str_buffer))\n",
    "\n",
    "#     # new_ints = []\n",
    "#     # for index, row in ints.iterrows(): \n",
    "#     #     if row['mat_area'] < row['wm_area']:\n",
    "#     #         keep = \"1\"\n",
    "#     #         keep_idx = row['mat_id']\n",
    "#     #     else: \n",
    "#     #         keep = \"2\"\n",
    "#     #         keep_idx = row['wm_id']\n",
    "#     #     keep_row = [keep_idx]\n",
    "#     #     for _col in sub_geoms.columns: \n",
    "#     #         if _col == \"geometry\": \n",
    "#     #             keep_row.append(row['geometry'])\n",
    "#     #         else: \n",
    "#     #             keep_row.append(row[f\"{_col}_{keep}\"])\n",
    "#     #     new_ints.append(keep_row)\n",
    "#     # add_ints = gpd.GeoDataFrame(new_ints, columns=[\"keep_idx\"] + list(sub_geoms.columns))\n",
    "\n",
    "#     # new_geoms = pd.concat([new_geoms, add_ints.drop(columns=[\"keep_idx\"])])\n",
    "#     # new_geoms = new_geoms.loc[~new_geoms.is_empty]\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5,5))\n",
    "#     new_geoms.plot(ax=ax, color=new_geoms['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "#     new_geoms.plot(ax=ax, color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "#     plt.show()\n",
    "\n",
    "#     contact_list.append(new_geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adf291",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_geoms = geoms[(geoms['brain_region'] == 'PU') & (geoms['lab'] == 'ucsd') & (geoms['donor'] == \"UCI5224\")]\n",
    "sub_geoms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda03177",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sub_geoms.plot(ax=ax, color=sub_geoms['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "sub_geoms.plot(ax=ax, color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9326425",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geoms = sub_geoms.copy()\n",
    "str_geoms = sub_geoms[sub_geoms['type'] == \"Striosome\"].copy()\n",
    "new_geoms.geometry = new_geoms.geometry.difference(str_geoms.unary_union.buffer(str_buffer))\n",
    "new_geoms.loc[str_geoms.index, str_geoms.columns] = str_geoms\n",
    "mat_geoms = new_geoms[new_geoms['type'] == \"Matrix\"].copy()\n",
    "wm_geoms = new_geoms[new_geoms['type'] == \"White_Matter\"].copy()\n",
    "new_geoms.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad900fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_geoms['wm_id'] = range(len(wm_geoms))\n",
    "mat_geoms['mat_id'] = range(len(mat_geoms))\n",
    "str_geoms['str_id'] = range(len(str_geoms))\n",
    "wm_geoms.shape, str_geoms.shape, mat_geoms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d37e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "ints = gpd.overlay(mat_geoms, wm_geoms, how='intersection')\n",
    "ints['mat_area'] = ints['mat_id'].apply(lambda x: mat_geoms.loc[mat_geoms['mat_id'] == x, 'geometry'].values[0].area)\n",
    "ints['wm_area'] = ints['wm_id'].apply(lambda x: wm_geoms.loc[wm_geoms['wm_id'] == x, 'geometry'].values[0].area)\n",
    "ints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59da72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "new_geoms.plot(ax=ax, color=new_geoms['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "new_geoms.plot(ax=ax, color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "ints.plot(ax=ax, color=\"yellow\", edgecolor='black', legend=True, alpha=0.5).axis(\"off\");\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove overlapping regions\n",
    "new_geoms.geometry = new_geoms.geometry.difference(ints.geometry.unary_union.buffer(str_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137125bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ints = []\n",
    "for index, row in ints.iterrows(): \n",
    "    if row['mat_area'] < row['wm_area']:\n",
    "        keep = \"1\"\n",
    "        keep_idx = row['mat_id']\n",
    "    else: \n",
    "        keep = \"2\"\n",
    "        keep_idx = row['wm_id']\n",
    "    keep_row = [keep_idx]\n",
    "    for _col in sub_geoms.columns: \n",
    "        if _col == \"geometry\": \n",
    "            keep_row.append(row['geometry'])\n",
    "        else: \n",
    "            keep_row.append(row[f\"{_col}_{keep}\"])\n",
    "    new_ints.append(keep_row)\n",
    "add_ints = gpd.GeoDataFrame(new_ints, columns=[\"keep_idx\"] + list(sub_geoms.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4098c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "new_geoms.plot(ax=ax, color=new_geoms['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "new_geoms.plot(ax=ax, color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "add_ints.plot(ax=ax, color=\"yellow\", edgecolor='black', legend=True, alpha=0.5).axis(\"off\");\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geoms = pd.concat([new_geoms, add_ints.drop(columns=[\"keep_idx\"])])\n",
    "new_geoms = new_geoms.loc[~new_geoms.is_empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "new_geoms.plot(ax=ax, color=new_geoms['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "new_geoms.plot(ax=ax, color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e666932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _donor in sub_geoms['donor'].unique():\n",
    "#     print(f\"Donor {_donor}:\")\n",
    "#     # display(sub_geoms[sub_geoms['donor'] == _donor]['type'].value_counts())\n",
    "#     sub_geomsd = sub_geoms[sub_geoms['donor'] == _donor].copy()\n",
    "#     fig, ax = plt.subplots(figsize=(5,5))\n",
    "#     sub_geomsd.plot(ax=ax, column=\"type\", color=sub_geomsd['type_color'], edgecolor='none', legend=True, alpha=0.1).axis(\"off\");\n",
    "#     sub_geomsd.plot(ax=ax, column=\"type\", color=\"none\", edgecolor='black', legend=True).axis(\"off\");\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
