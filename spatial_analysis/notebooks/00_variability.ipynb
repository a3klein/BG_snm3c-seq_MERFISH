{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c41d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "\n",
    "# import scanpy as sc\n",
    "# import scipy.stats\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from datetime import datetime \n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
    "image_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/images\"\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna = ad.read_h5ad(\"/home/x-aklein2/projects/aklein/BICAN/data/reference/AIT/AIT_PU.h5ad\", backed='r')\n",
    "adata_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f61ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cells = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc7f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\"Class\", \"Subclass\", \"Group\", \"Cluster\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52dbe1",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _level in levels: \n",
    "    cell_types = adata_rna.obs[_level].unique().tolist()\n",
    "    for _cell_type in cell_types:\n",
    "        adata_sub = adata_rna[adata_rna.obs[_level] == _cell_type, :].copy()\n",
    "        adata_sub.layers['counts'] = adata_sub.raw.X.copy()\n",
    "        if adata_sub.n_obs > max_cells:\n",
    "            adata_sub = adata_sub[adata_sub.obs.sample(max_cells).index, :].copy()\n",
    "        expr = adata_sub.X.toarray()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e394547",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2 = train_test_split(expr, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c63f83",
   "metadata": {},
   "source": [
    "## Pearson Correlation \n",
    "Not working so far! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96db165",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_mean = np.mean(X1, axis=0)\n",
    "X2_mean = np.mean(X2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_list = []\n",
    "for _thr in np.arange(0, 5, 0.05): \n",
    "    mask = (X1_mean >= _thr) & (X2_mean >= _thr)\n",
    "    thr_list.append((_thr, np.sum(mask)))\n",
    "    # X1_mean_thr = X1_mean[mask]\n",
    "    # X2_mean_thr = X2_mean[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_list = []\n",
    "for _thr in np.arange(0, 5, 0.05): \n",
    "    mask = (X1_mean >= _thr) & (X2_mean >= _thr)\n",
    "    thr_list.append((_thr, np.sum(mask)))\n",
    "    # X1_mean_thr = X1_mean[mask]\n",
    "    # X2_mean_thr = X2_mean[mask]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3), dpi=150)\n",
    "thr_df = pd.DataFrame(thr_list, columns=[\"Threshold\", \"Num_genes\"])\n",
    "sns.lineplot(data=thr_df, x=\"Threshold\", y=\"Num_genes\", ax=ax)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Expression threshold\")\n",
    "ax.set_ylabel(\"Number of genes\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(X1_mean, X2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83299564",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_sum = np.sum(X1, axis=0)\n",
    "X2_sum = np.sum(X2, axis=0)\n",
    "scipy.stats.pearsonr(X1_sum, X2_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd676472",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.t.sf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d9641",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_list = []\n",
    "corr = []\n",
    "for _thr in np.arange(0, 1000, 1): \n",
    "    mask = (X1_sum >= _thr) & (X2_sum >= _thr)\n",
    "    thr_list.append((_thr, np.sum(mask)))\n",
    "    X1_sum_thr = X1_sum[mask]\n",
    "    X2_sum_thr = X2_sum[mask]\n",
    "    pcorr, _ = scipy.stats.pearsonr(X1_sum_thr, X2_sum_thr)\n",
    "    corr.append((pcorr, _thr))\n",
    "thr_df = pd.DataFrame(thr_list, columns=[\"Threshold\", \"Num_genes\"])\n",
    "corr_df = pd.DataFrame(corr, columns=[\"Pearson_corr\", \"Threshold\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8,3), dpi=150)\n",
    "ax = axes[0]\n",
    "sns.lineplot(data=thr_df, x=\"Threshold\", y=\"Num_genes\", ax=ax)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Expression threshold\")\n",
    "ax.set_ylabel(\"Number of genes\")\n",
    "\n",
    "ax = axes[1]\n",
    "sns.lineplot(data=corr_df, x=\"Threshold\", y=\"Pearson_corr\", ax=ax)\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel(\"Expression threshold\")\n",
    "ax.set_ylabel(\"Pearson correlation\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b99b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X1_sum == 0).sum(), (X2_sum == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd077fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f262c98",
   "metadata": {},
   "source": [
    "## PCA loadings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090053c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.experimental.pp.highly_variable_genes(\n",
    "    adata_sub, n_top_genes=5000, layer='counts', subset=False,\n",
    ")\n",
    "n_hvgs = int(adata_sub.var['highly_variable'].sum())\n",
    "print(f\"Number of highly variable genes: {n_hvgs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e29c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pca = adata_sub[:, adata_sub.var['highly_variable']].copy()\n",
    "sc.pp.scale(adata_pca, max_value=10)\n",
    "sc.tl.pca(adata_pca, n_comps=100, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc52df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained = adata_pca.uns['pca']['variance_ratio']\n",
    "cum_expl = np.cumsum(explained)\n",
    "n_pc_80 = int((cum_expl < 0.8).sum() + 1)\n",
    "n_pc_90 = int((cum_expl < 0.9).sum() + 1)\n",
    "print(f\"Number of PCs to explain 80% variance: {n_pc_80}\")\n",
    "print(f\"Number of PCs to explain 90% variance: {n_pc_90}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451155d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = adata_pca.varm['PCs']\n",
    "weights = explained[:loadings.shape[1]]\n",
    "gene_scores = (loadings**2 * weights).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ff5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df = pd.DataFrame({\n",
    "    \"gene\" : adata_pca.var_names, \n",
    "    \"gene_score\": gene_scores\n",
    "}).sort_values(\"gene_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ce5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_frac = 0.10\n",
    "k = max(1, int(top_frac * gene_df.shape[0]))\n",
    "variable_genes_pca = gene_df.head(k)\n",
    "print(f\"[PCA approach] #genes in top {int(top_frac*100)}% by PCA variance score: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01571589",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda84f7",
   "metadata": {},
   "source": [
    "## SCVI NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scvi\n",
    "from anndata import AnnData\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "def nb_within_cluster_variability(\n",
    "    adata: AnnData,\n",
    "    cluster_key: str,\n",
    "    cluster_value: str,\n",
    "    *,\n",
    "    counts_layer: str = \"counts\",\n",
    "    batch_key: Optional[str] = None,\n",
    "    model: Optional[scvi.model.SCVI] = None,\n",
    "    max_epochs: int = 100,\n",
    "    n_latent: int = 10,\n",
    "    top_frac: float = 0.10,\n",
    "    robust_call: bool = True,\n",
    "    seed: int = 0,\n",
    "    return_residuals: bool = False,\n",
    "    # New ↓↓↓\n",
    "    max_cells_per_cluster: Optional[int] = None,\n",
    "    stratify_by: Optional[str] = None,   # e.g., \"batch\" to preserve batch proportions\n",
    "    min_cells_required: int = 20,        # sanity check for tiny clusters after downsampling\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Estimate within-cluster gene variability under a Negative Binomial model using scVI,\n",
    "    with optional downsampling of the target cluster.\n",
    "\n",
    "    New parameters\n",
    "    --------------\n",
    "    max_cells_per_cluster : int or None\n",
    "        If set and the cluster has more cells than this, downsample without replacement\n",
    "        to this target size (optionally stratified by `stratify_by`).\n",
    "    stratify_by : str or None\n",
    "        Column in `adata.obs` used to stratify the downsampling (preserves proportions).\n",
    "        Only applies within the target cluster.\n",
    "    min_cells_required : int\n",
    "        Raise an error if the final cluster size is below this threshold.\n",
    "    \"\"\"\n",
    "    # -------------------------\n",
    "    # Ensure counts layer\n",
    "    # -------------------------\n",
    "    if counts_layer not in adata.layers:\n",
    "        adata.layers[counts_layer] = adata.X.copy()\n",
    "\n",
    "    # -------------------------\n",
    "    # Train or reuse scVI model\n",
    "    # -------------------------\n",
    "    if model is None:\n",
    "        adata_nb = adata.copy()\n",
    "        scvi.settings.seed = seed\n",
    "        scvi.model.SCVI.setup_anndata(adata_nb, layer=counts_layer, batch_key=batch_key)\n",
    "        model = scvi.model.SCVI(adata_nb, n_layers=2, n_latent=n_latent, gene_likelihood=\"nb\")\n",
    "        model.train(max_epochs=max_epochs, early_stopping=True, plan_kwargs={\"lr\": 1e-3})\n",
    "    else:\n",
    "        adata_nb = adata  # assume model already aligned to this AnnData\n",
    "\n",
    "    # -------------------------\n",
    "    # Subset to the cluster\n",
    "    # -------------------------\n",
    "    if cluster_key not in adata_nb.obs.columns:\n",
    "        raise KeyError(f\"cluster_key '{cluster_key}' not found in adata.obs\")\n",
    "\n",
    "    mask = (adata_nb.obs[cluster_key].astype(str) == str(cluster_value)).values\n",
    "    if mask.sum() == 0:\n",
    "        raise ValueError(f\"No cells found for {cluster_key} == '{cluster_value}'\")\n",
    "\n",
    "    # Potential downsampling indices (within cluster)\n",
    "    cluster_idx = np.where(mask)[0]\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if max_cells_per_cluster is not None and len(cluster_idx) > max_cells_per_cluster:\n",
    "        if stratify_by is None:\n",
    "            # Simple random sample without replacement\n",
    "            sampled_idx = rng.choice(cluster_idx, size=max_cells_per_cluster, replace=False)\n",
    "        else:\n",
    "            # Stratified sampling by adata.obs[stratify_by] within the cluster\n",
    "            if stratify_by not in adata_nb.obs.columns:\n",
    "                raise KeyError(f\"stratify_by '{stratify_by}' not found in adata.obs\")\n",
    "\n",
    "            labels = adata_nb.obs[stratify_by].astype(str).values\n",
    "            # counts per stratum in the cluster\n",
    "            unique, counts = np.unique(labels[cluster_idx], return_counts=True)\n",
    "            props = counts / counts.sum()\n",
    "            # initial quota per stratum\n",
    "            quotas = np.floor(props * max_cells_per_cluster).astype(int)\n",
    "            # distribute any remainder\n",
    "            remainder = max_cells_per_cluster - quotas.sum()\n",
    "            if remainder > 0:\n",
    "                # assign remainder to strata with largest fractional parts\n",
    "                fracs = (props * max_cells_per_cluster) - np.floor(props * max_cells_per_cluster)\n",
    "                order = np.argsort(-fracs)\n",
    "                for j in order[:remainder]:\n",
    "                    quotas[j] += 1\n",
    "\n",
    "            # sample within each stratum\n",
    "            sampled_idx_list = []\n",
    "            for lab, q in zip(unique, quotas):\n",
    "                stratum_idx = cluster_idx[labels[cluster_idx] == lab]\n",
    "                if q > len(stratum_idx):\n",
    "                    q = len(stratum_idx)  # safety, in case of rounding\n",
    "                if q > 0:\n",
    "                    sampled_idx_list.append(rng.choice(stratum_idx, size=q, replace=False))\n",
    "            sampled_idx = np.concatenate(sampled_idx_list) if len(sampled_idx_list) else np.array([], dtype=int)\n",
    "\n",
    "        final_idx = np.sort(sampled_idx)\n",
    "    else:\n",
    "        final_idx = cluster_idx\n",
    "\n",
    "    if final_idx.size < min_cells_required:\n",
    "        raise ValueError(\n",
    "            f\"Final cluster size ({final_idx.size}) is below min_cells_required={min_cells_required}.\"\n",
    "        )\n",
    "\n",
    "    adata_c = adata_nb[final_idx].copy()\n",
    "\n",
    "    # Observed counts (cells x genes)\n",
    "    X = adata_c.layers[counts_layer]\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        X = X.toarray()\n",
    "    X = X.astype(np.float32, copy=False)\n",
    "\n",
    "    # -------------------------\n",
    "    # NB parameters from scVI\n",
    "    # -------------------------\n",
    "    lik = model.get_likelihood_parameters(adata=adata_c)\n",
    "    mu = lik[\"mu\"]          # (cells x genes)\n",
    "    theta = lik[\"theta\"]    # (genes,)\n",
    "\n",
    "    # -------------------------\n",
    "    # Pearson residuals & per-gene variance\n",
    "    # -------------------------\n",
    "    den = np.sqrt(mu + (mu ** 2) / theta[None, :]) + 1e-8\n",
    "    residuals = (X - mu) / den\n",
    "    res_var = residuals.var(axis=0, ddof=1)\n",
    "\n",
    "    gene_table = pd.DataFrame({\n",
    "        \"gene\": adata_c.var_names,\n",
    "        \"residual_variance\": res_var\n",
    "    }).sort_values(\"residual_variance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Top-fraction call\n",
    "    n_genes = gene_table.shape[0]\n",
    "    k = max(1, int(round(top_frac * n_genes)))\n",
    "    top_fraction_genes = gene_table.head(k).copy()\n",
    "\n",
    "    result: Dict[str, Any] = {\n",
    "        \"cluster_id\": str(cluster_value),\n",
    "        \"gene_table\": gene_table,\n",
    "        \"n_genes\": n_genes,\n",
    "        \"top_fraction_genes\": top_fraction_genes,\n",
    "        \"n_top_fraction\": k,\n",
    "        \"final_n_cells\": int(adata_c.n_obs),\n",
    "        \"downsampled\": bool(final_idx.size < cluster_idx.size),\n",
    "        \"sampled_cell_indices\": final_idx,  # indices into the original AnnData\n",
    "        \"stratify_by\": stratify_by,\n",
    "        \"max_cells_per_cluster\": max_cells_per_cluster,\n",
    "    }\n",
    "\n",
    "    if robust_call:\n",
    "        med = float(np.median(res_var))\n",
    "        mad = float(np.median(np.abs(res_var - med)) + 1e-8)\n",
    "        thr = med + 3 * 1.4826 * mad\n",
    "        thr = float(max(1.0, thr))  # NB baseline variance ~1\n",
    "        robust_mask = res_var > thr\n",
    "        robust_genes = gene_table.loc[robust_mask].copy()\n",
    "        result.update({\n",
    "            \"robust_genes\": robust_genes,\n",
    "            \"n_robust\": robust_genes.shape[0],\n",
    "            \"robust_threshold\": thr,\n",
    "            \"median_res_var\": med,\n",
    "            \"mad_res_var\": mad,\n",
    "        })\n",
    "\n",
    "    if return_residuals:\n",
    "        result[\"residuals\"] = residuals  # cells x genes (after any downsampling)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b0c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna.layers['counts'] = adata_rna.raw.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f09c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_rna.obs[levels[0]].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774d56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time scVI training (reuse model across clusters if you want)\n",
    "# If you already have raw counts in adata.layers[\"counts\"], you're set.\n",
    "res = nb_within_cluster_variability(\n",
    "    adata_rna,\n",
    "    cluster_key=levels[0],\n",
    "    cluster_value=adata_rna.obs[levels[0]].unique()[0],\n",
    "    counts_layer=\"counts\",   # or whatever your raw counts layer is\n",
    "    batch_key=None,          # e.g., \"batch\" if present\n",
    "    max_epochs=100,\n",
    "    max_cells_per_cluster=2000,\n",
    "    top_frac=0.10,\n",
    "    robust_call=True,\n",
    ")\n",
    "\n",
    "print(\"Cluster:\", res[\"cluster_id\"])\n",
    "print(\"# genes (top 10%):\", res[\"n_top_fraction\"])\n",
    "print(\"# genes (robust):\", res.get(\"n_robust\", \"n/a\"))\n",
    "res[\"gene_table\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556122f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sub.var['highly_variable'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sub.raw.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969b293",
   "metadata": {},
   "source": [
    "## Dispersion based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"/home/x-aklein2/projects/aklein/BICAN/BG/data/cluster_dispersion\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e35fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "def calculate_hvf_svr(adata, max_cells = 50000, min_cells = 20): \n",
    "    if adata.n_obs > max_cells:\n",
    "        adata = adata[adata.obs.sample(max_cells).index, :].copy()\n",
    "    if adata.n_obs < min_cells:\n",
    "        raise ValueError(f\"Not enough cells ({adata.n_obs}) to calculate HVF.\")\n",
    "    expr = adata.X.toarray().copy()\n",
    "    expr_mean = np.mean(expr, axis=0)\n",
    "    expr_var = np.var(expr, axis=0, ddof=1)\n",
    "    dispersion = expr_var / (expr_mean + 1e-8)\n",
    "    log2_disp = np.log2(dispersion + 1e-8)\n",
    "    log2_expr_mean = np.log2(expr_mean + 1e-8)\n",
    "    X = np.vstack([log2_expr_mean]).T\n",
    "\n",
    "    svr_gamma = 1000 / X.shape[0]\n",
    "    svr = SVR(kernel='rbf', C=1.0, gamma=svr_gamma)\n",
    "    svr.fit(X, log2_disp)\n",
    "\n",
    "    score = log2_disp - svr.predict(X)\n",
    "\n",
    "    hvf_df = pd.DataFrame({\n",
    "        \"gene\": adata.var_names,\n",
    "        \"svr_score\": score,\n",
    "        \"dispersion\": dispersion\n",
    "    }).sort_values(\"svr_score\", ascending=False)\n",
    "\n",
    "    return hvf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hvf_df = calculate_hvf_svr(adata_rna)\n",
    "# fout = output_path / f\"hvf_svr_all.csv\"\n",
    "# hvf_df.to_csv(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b17b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _level in levels:\n",
    "#     for _cell_type in adata_rna.obs[_level].unique().tolist():\n",
    "#         print(f\"Level: {_level}, Cell type: {_cell_type}, #cells: {(adata_rna.obs[_level] == _cell_type).sum()}\")\n",
    "#         try: \n",
    "#             hvf_df = calculate_hvf_svr(adata_rna[adata_rna.obs[_level] == _cell_type, :])\n",
    "#         except ValueError as e:\n",
    "#             print(f\"  Skipping {_cell_type} due to error: {e}\")\n",
    "#             continue\n",
    "#         out_ct = _cell_type.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "#         fout = output_path / f\"hvf_svr_{_level}_{out_ct}.csv\"\n",
    "#         hvf_df.to_csv(fout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19808d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: \n",
    "# - Load at the class, subclass, group, and cluster level \n",
    "# - For each gene look at the ratio of both its dispersion and its score to the dispersion / score from entire dataset calculations \n",
    "# - For each gene classify the difference between the new and original as its value on a min-max scaling with the min is 0 and the max is the original value \n",
    "# - (account for side cases where there was 0 dispersion in old and new!) \n",
    "# - For varying thresholds np.arange(0, 2, 0.05) get the count per cell type for genes that are above that said threshold\n",
    "# - plot the histogram colored by level for those counts (different histogram for the different thresholds!). # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f870449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hvf_df_all = pd.read_csv(output_path / \"hvf_svr_all.csv\", index_col=0)\n",
    "# hvf_df_all = hvf_df_all.set_index(\"gene\")\n",
    "# for _level in levels:\n",
    "#     for _cell_type in adata_rna.obs[_level].unique().tolist():\n",
    "#         out_ct = _cell_type.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "#         try: \n",
    "#             hvf_df = pd.read_csv(output_path / f\"hvf_svr_{_level}_{out_ct}.csv\", index_col=0)\n",
    "#             hvf_df = hvf_df.set_index(\"gene\")\n",
    "#         except FileNotFoundError as e:\n",
    "#             print(f\"  Skipping {_cell_type} due to error: {e}\")\n",
    "#             continue\n",
    "#         hvf_df = hvf_df.join(hvf_df_all, lsuffix=\"_sub\", rsuffix=\"_all\", how=\"inner\")\n",
    "#         hvf_df['dispersion_ratio'] = hvf_df['dispersion_sub'] / (hvf_df['dispersion_all'] + 1e-8)\n",
    "#         hvf_df['score_ratio'] = hvf_df['svr_score_sub'] / (hvf_df['svr_score_all'] + 1e-8)\n",
    "#         # min-max scaling of the ratios \n",
    "#         # hvf_df['dispersion_ratio_mm'] = (hvf_df['dispersion_ratio'] - hvf_df['dispersion_ratio'].min()) / (hvf_df['dispersion_ratio'].max() - hvf_df['dispersion_ratio'].min() + 1e-8)\n",
    "#         # hvf_df['score_ratio_mm'] = (hvf_df['score_ratio'] - hvf_df['score_ratio'].min()) / (hvf_df['score_ratio'].max() - hvf_df['score_ratio'].min() + 1e-8)\n",
    "#         out_ct = _cell_type.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "#         fout = output_path / f\"hvf_svr_ratios_{_level}_{out_ct}.csv\"\n",
    "#         hvf_df.to_csv(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_levels = {}\n",
    "for _level in levels:\n",
    "    level_specific = {}\n",
    "    for _cell_type in adata_rna.obs[_level].unique().tolist():\n",
    "        out_ct = _cell_type.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        try: \n",
    "            hvf_df = pd.read_csv(output_path / f\"hvf_svr_ratios_{_level}_{out_ct}.csv\", index_col=0)\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"  Skipping {_cell_type} due to error: {e}\")\n",
    "            continue\n",
    "        thr_list = []\n",
    "        for thr in np.arange(0.05, 2.05, 0.05):\n",
    "            count_disp = (hvf_df['dispersion_ratio'] > thr).sum()\n",
    "            count_score = (hvf_df['score_ratio'] > thr).sum()\n",
    "            thr_list.append((thr, count_disp, count_score))\n",
    "        level_specific[_cell_type] = thr_list\n",
    "    all_levels[_level] = level_specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_level_histograms_grid(data, mode='D'):\n",
    "    \"\"\"\n",
    "    For each threshold, plot a subplot with 4 histograms (one for each level).\n",
    "    mode: 'D' for dispersion, 'S' for score\n",
    "    Plots density instead of frequency.\n",
    "    \"\"\"\n",
    "    levels = list(data.keys())\n",
    "    # Assume all levels have the same thresholds\n",
    "    thresholds = set()\n",
    "    for level in levels:\n",
    "        for vals in data[level].values():\n",
    "            thresholds.update([t for t, _, _ in vals])\n",
    "    thresholds = sorted(thresholds)\n",
    "    n = len(thresholds)\n",
    "    ncols = math.ceil(math.sqrt(n))\n",
    "    nrows = math.ceil(n / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4*ncols, 4*nrows), squeeze=False)\n",
    "    for idx, threshold in enumerate(thresholds):\n",
    "        row, col = divmod(idx, ncols)\n",
    "        ax = axes[row][col]\n",
    "        for level in levels:\n",
    "            cell_types = list(data[level].keys())\n",
    "            values = []\n",
    "            for ct in cell_types:\n",
    "                for t, count_d, count_s in data[level][ct]:\n",
    "                    if t == threshold:\n",
    "                        values.append(count_d if mode == 'D' else count_s)\n",
    "                        break\n",
    "            ax.hist(values, bins=20, alpha=0.5, label=level, density=True)\n",
    "        ax.set_title(f'Threshold {threshold:.2f}')\n",
    "        ax.set_xlabel('Count')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "    # Hide unused subplots\n",
    "    for idx in range(n, nrows * ncols):\n",
    "        row, col = divmod(idx, ncols)\n",
    "        fig.delaxes(axes[row][col])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# plot_level_histograms_grid(all_levels, mode='D')  # For dispersion\n",
    "# plot_level_histograms_grid(all_levels, mode='S')  # For score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bfd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_counts_per_threshold(data, mode='D'):\n",
    "    \"\"\"\n",
    "    For each threshold, calculate the median count across cell types for each level.\n",
    "    mode: 'D' for dispersion, 'S' for score\n",
    "    Returns a DataFrame with thresholds as index and levels as columns.\n",
    "    \"\"\"\n",
    "    levels = list(data.keys())\n",
    "    # Assume all levels have the same thresholds\n",
    "    thresholds = set()\n",
    "    for level in levels:\n",
    "        for vals in data[level].values():\n",
    "            thresholds.update([t for t, _, _ in vals])\n",
    "    thresholds = sorted(thresholds)\n",
    "    n = len(thresholds)\n",
    "    ncols = math.ceil(math.sqrt(n))\n",
    "    nrows = math.ceil(n / ncols)\n",
    "\n",
    "    thr_lists = []\n",
    "    for idx, threshold in enumerate(thresholds):\n",
    "        row, col = divmod(idx, ncols)\n",
    "        medians = []\n",
    "        for level in levels:\n",
    "            cell_types = list(data[level].keys())\n",
    "            values = []\n",
    "            for ct in cell_types:\n",
    "                for t, count_d, count_s in data[level][ct]:\n",
    "                    if t == threshold:\n",
    "                        values.append(count_d if mode == 'D' else count_s)\n",
    "                        break\n",
    "            medians.append(np.median(values))\n",
    "        thr_lists.append((threshold, *medians))\n",
    "    df_meds = pd.DataFrame(thr_lists, columns=[\"Threshold\"] + levels).set_index(\"Threshold\")\n",
    "    return df_meds\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7467869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meds_D = calculate_median_counts_per_threshold(all_levels, mode='D')  # For dispersion\n",
    "df_meds_S = calculate_median_counts_per_threshold(all_levels, mode='S')  # For score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6503787",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "sns.lineplot(data=df_meds_D, ax=ax)\n",
    "ax.set_xlabel(\"Thresholded Dispersion Ratio\")\n",
    "ax.set_ylabel(\"Median count\")\n",
    "ax.set_title(\"Median Gene Counts Above Dispersion Ratio Threshold by Level\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce1e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "sns.lineplot(data=df_meds_S, ax=ax)\n",
    "ax.set_xlabel(\"Thresholded Score Ratio\")\n",
    "ax.set_ylabel(\"Median count\")\n",
    "ax.set_title(\"Median Gene Counts Above Score Ratio Threshold by Level\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c924750",
   "metadata": {},
   "source": [
    "### Specific Gene Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae077c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a5fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a lineage: \n",
    "class_vc = adata_rna.obs.loc[adata_rna.obs['Class'] == \"CN LGE GABA\", 'Subclass'].value_counts()\n",
    "rprint(class_vc[class_vc > 0].index.tolist())\n",
    "subclass_vc = adata_rna.obs.loc[adata_rna.obs['Subclass'] == \"STR D2 MSN\", 'Group'].value_counts()\n",
    "rprint(subclass_vc[subclass_vc > 0].index.tolist())\n",
    "group_vc = adata_rna.obs.loc[adata_rna.obs['Group'] == \"STRd D2 Matrix MSN\", 'Cluster'].value_counts()\n",
    "rprint(group_vc[group_vc > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee80267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_expr_for_celltype(\n",
    "    adata : ad.AnnData, \n",
    "    level : str | list[str],\n",
    "    cell_type : str | list[str],\n",
    "    gene : str | list[str] = None,\n",
    "    layer : str = None,\n",
    "    max_cells : int = 10000,\n",
    "): \n",
    "    if isinstance(gene, str):\n",
    "        gene = [gene]\n",
    "    if isinstance(level, str):\n",
    "        level = [level]\n",
    "    if isinstance(cell_type, str):\n",
    "        cell_type = [cell_type]\n",
    "    if len(level) != len(cell_type):\n",
    "        raise ValueError(\"Length of level and cell_type must be the same.\")\n",
    "    expr_list = []\n",
    "    for l, ct in zip(level, cell_type):\n",
    "        if l not in adata.obs.columns:\n",
    "            raise KeyError(f\"Level '{l}' not found in adata.obs\")\n",
    "        adata_sub = adata[adata.obs[l] == ct].to_memory().copy()\n",
    "        print(f\"Level: {l}, Cell type: {ct}, #cells: {adata_sub.shape[0]}\")\n",
    "        if adata_sub.shape[0] == 0:\n",
    "            raise ValueError(f\"No cells found for the specified level(s) and cell_type(s).\")\n",
    "        elif adata_sub.shape[0] > max_cells and gene is not None:\n",
    "            adata_sub = adata_sub[adata_sub.obs.sample(max_cells).index, adata_sub.var_names.isin(gene)].copy()\n",
    "        elif adata_sub.shape[0] > max_cells:\n",
    "            adata_sub = adata_sub[adata_sub.obs.sample(max_cells).index, :].copy()\n",
    "        elif gene is not None:\n",
    "            adata_sub = adata_sub[:, adata_sub.var_names.isin(gene)].copy()\n",
    "        \n",
    "        if layer is None:\n",
    "            expr = adata_sub.X.toarray()\n",
    "        else: \n",
    "            expr = adata_sub.layers[layer]\n",
    "        \n",
    "        if hasattr(expr, \"toarray\"):\n",
    "            expr = expr.toarray()\n",
    "        expr_list.append(expr)\n",
    "        del expr\n",
    "    gene_list = adata_sub.var_names if gene is None else gene\n",
    "    del adata_sub\n",
    "    return expr_list, gene_list\n",
    "    # expr_mean = np.mean(expr, axis=0)\n",
    "    # expr_var = np.var(expr, axis=0, ddof=1)\n",
    "    # dispersion = expr_var / (expr_mean + 1e-8)\n",
    "    # df = pd.DataFrame({\n",
    "    #     \"gene\": adata_sub.var_names,\n",
    "    #     \"mean_expr\": expr_mean,\n",
    "    #     \"variance\": expr_var,\n",
    "    #     \"dispersion\": dispersion\n",
    "    # }).set_index(\"gene\")\n",
    "    # return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bda2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expr = get_gene_expr_for_celltype(\n",
    "#     adata_rna, \n",
    "#     level = \"Subclass\",\n",
    "#     cell_type = \"STR D2 MSN\",\n",
    "#     gene = \"DRD2\",\n",
    "#     max_cells=10000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79def493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topn_dispersion_genes(\n",
    "    level: str | list[str], \n",
    "    cell_type: str | list[str],\n",
    "    n: int = 100,\n",
    "    data_path = Path(\"/home/x-aklein2/projects/aklein/BICAN/BG/data/cluster_dispersion\")\n",
    "):\n",
    "    if isinstance(level, str):\n",
    "        level = [level]\n",
    "    if isinstance(cell_type, str):\n",
    "        cell_type = [cell_type]\n",
    "    if len(level) != len(cell_type):\n",
    "        raise ValueError(\"Length of level and cell_type must be the same.\")\n",
    "    dfs = []\n",
    "    for l, ct in zip(level, cell_type):\n",
    "        out_ct = ct.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        try: \n",
    "            hvf_df = pd.read_csv(data_path / f\"hvf_svr_ratios_{l}_{out_ct}.csv\", index_col=0)\n",
    "            # hvf_df = hvf_df.set_index(\"gene\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"  Skipping {ct} due to error: {e}\")\n",
    "            continue\n",
    "        hvf_df_top = hvf_df.sort_values(\"svr_score_sub\", ascending=False).head(n)\n",
    "        hvf_df_top['category'] = 'top'\n",
    "        hvf_df_bottom = hvf_df.sort_values(\"svr_score_sub\", ascending=True).head(n)\n",
    "        hvf_df_bottom['category'] = 'bottom'\n",
    "        hvf_df = pd.concat([hvf_df_top, hvf_df_bottom], axis=0)\n",
    "        hvf_df = hvf_df.reset_index().copy()\n",
    "        hvf_df['level'] = l\n",
    "        hvf_df['cell_type'] = ct\n",
    "        dfs.append(hvf_df)\n",
    "    if len(dfs) == 0:\n",
    "        raise ValueError(\"No dataframes to concatenate.\")\n",
    "    df_all = pd.concat(dfs, axis=0)\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_topn_dispersion_genes(\n",
    "    level = [\"Class\", \"Subclass\", \"Group\"],\n",
    "    cell_type = [\"CN LGE GABA\", \"STR D2 MSN\", \"STRd D2 Matrix MSN\"],\n",
    "    n = 100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95902706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['level'] == 'Class'].sort_values(\"svr_score_sub\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46effb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_list, var_names = get_gene_expr_for_celltype(\n",
    "    adata_rna, \n",
    "    level = [\"Class\", \"Subclass\", \"Group\", \"Cluster\"],\n",
    "    cell_type = [\"CN LGE GABA\", \"STR D2 MSN\", \"STRd D2 Matrix MSN\", \"Human-84\"],\n",
    "    max_cells=50000, \n",
    "    gene=[\"GPC5\", \"LRRC7\", \"XIST\", \"CHRM3\", \"FTX\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd276cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_expr = expr_list[0]\n",
    "subclass_expr = expr_list[1]\n",
    "group_expr = expr_list[2]\n",
    "cluster_expr = expr_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d1208",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_expr.max(axis=0), subclass_expr.max(axis=0), group_expr.max(axis=0), cluster_expr.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _id, _gene in enumerate(var_names):\n",
    "    fig, ax = plt.subplots(figsize=(6,4), dpi=150)\n",
    "    sns.histplot(class_expr[:, _id].flatten(), label=\"Class: CN LGE GABA\", ax=ax, stat=\"probability\", alpha=0.5, binwidth=0.1)\n",
    "    sns.histplot(subclass_expr[:, _id].flatten(), label=\"Subclass: STR D2 MSN\", ax=ax, stat=\"probability\", alpha=0.5, binwidth=0.1)\n",
    "    sns.histplot(group_expr[:, _id].flatten(), label=\"Group: STRd D2 Matrix MSN\", ax=ax, stat=\"probability\", alpha=0.5, binwidth=0.1)\n",
    "    sns.histplot(cluster_expr[:, _id].flatten(), label=\"Cluster: Human-84\", ax=ax, stat=\"probability\", alpha=0.5, binwidth=0.1)\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_xlabel(\"Expression\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(f\"Expression Distribution of {_gene} Across Cell Types\")\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ec62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32d397",
   "metadata": {},
   "source": [
    "## Call DEGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2995342",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(adata_sub.shape[0])\n",
    "x1_indices, x2_indices = train_test_split(indices, test_size=0.5, random_state=13)\n",
    "x1_index = adata_sub.obs.iloc[x1_indices].index\n",
    "x2_index = adata_sub.obs.iloc[x2_indices].index\n",
    "adata_sub.obs.loc[x1_index, \"split\"] = \"X1\"\n",
    "adata_sub.obs.loc[x2_index, \"split\"] = \"X2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62853c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spida.utilities._degs import call_degs_by_celltype, summarize_deg_results, plot_deg_summary, plot_volcano\n",
    "# def call_degs_by_celltype(\n",
    "#     adata: ad.AnnData,\n",
    "#     celltype_col: str,\n",
    "#     layer: str | None = None,\n",
    "#     min_cells: int = 10,\n",
    "#     max_cells: int = 50000,\n",
    "#     min_genes: int = 100,\n",
    "#     logfc_threshold: float = 0.25,\n",
    "#     pval_threshold: float = 0.05,\n",
    "#     method: str = 'wilcoxon',\n",
    "#     correction_method: str = 'benjamini-hochberg',\n",
    "#     n_genes: int | None = None,\n",
    "#     save_results: bool = True,\n",
    "#     output_dir: str | None = None,\n",
    "#     verbose: bool = False\n",
    "# ) -> dict[str, pd.DataFrame]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sub = adata_sub[:, adata_sub.var['highly_variable']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = call_degs_by_celltype(\n",
    "    adata_sub, \n",
    "    celltype_col='split',\n",
    "    layer=None,\n",
    "    min_cells=10,\n",
    "    max_cells=50000,\n",
    "    min_genes=100,\n",
    "    logfc_threshold=0.25,\n",
    "    pval_threshold=0.05,\n",
    "    method='wilcoxon',\n",
    "    correction_method='benjamini-hochberg',\n",
    "    n_genes=None,\n",
    "    save_results=False,\n",
    "    output_dir=None,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79cb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['X1']['significant'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963287f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary\n",
    "summary_subclass = summarize_deg_results(results, top_n=10)\n",
    "print(\"\\nSubclass-level DEG Summary:\")\n",
    "print(summary_subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(\n",
    "    adata_sub, \n",
    "    groupby='split',\n",
    "    groups=[celltype],\n",
    "    reference='others',\n",
    "    method=method,\n",
    "    use_raw=False,\n",
    "    layer=layer,\n",
    "    n_genes=adata_ds.n_vars if n_genes is None else n_genes,\n",
    "    tie_correct=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326654b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.rank_genes_groups(\n",
    "    adata_ds,\n",
    "    groupby='temp_groups',\n",
    "    groups=[celltype],\n",
    "    reference='others',\n",
    "    method=method,\n",
    "    use_raw=False,\n",
    "    layer=layer,\n",
    "    n_genes=adata_ds.n_vars if n_genes is None else n_genes,\n",
    "    tie_correct=True\n",
    ")\n",
    "\n",
    "# Extract results\n",
    "result = sc.get.rank_genes_groups_df(\n",
    "    adata_ds, \n",
    "    group=celltype,\n",
    "    pval_cutoff=1.0,  # Get all genes, filter later\n",
    "    log2fc_min=None   # Get all genes, filter later\n",
    ")\n",
    "\n",
    "# Add multiple testing correction\n",
    "if len(result) > 0:\n",
    "    if correction_method == 'benjamini-hochberg':\n",
    "        rejected, pvals_corrected, _, _ = multipletests(\n",
    "            result['pvals'], \n",
    "            method='fdr_bh'\n",
    "        )\n",
    "        result['pvals_adj'] = pvals_corrected\n",
    "    elif correction_method == 'bonferroni':\n",
    "        rejected, pvals_corrected, _, _ = multipletests(\n",
    "            result['pvals'], \n",
    "            method='bonferroni'\n",
    "        )\n",
    "        result['pvals_adj'] = pvals_corrected\n",
    "    else:\n",
    "        result['pvals_adj'] = result['pvals']\n",
    "    \n",
    "    # Add significance flags\n",
    "    result['significant'] = (\n",
    "        (result['pvals_adj'] < pval_threshold) & \n",
    "        (abs(result['logfoldchanges']) > logfc_threshold)\n",
    "    )\n",
    "    \n",
    "    # Sort by adjusted p-value and log fold change\n",
    "    result = result.sort_values(['significant', 'pvals_adj', 'logfoldchanges'], \n",
    "                                ascending=[False, True, False])\n",
    "    \n",
    "    # Add cell type information\n",
    "    result['cell_type'] = celltype\n",
    "    result['comparison'] = f\"{celltype}_vs_others\"\n",
    "    \n",
    "    deg_results[celltype] = result\n",
    "    \n",
    "    n_sig = result['significant'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc39d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
