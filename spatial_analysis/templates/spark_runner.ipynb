{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdecc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json \n",
    "import math\n",
    "import shutil\n",
    "import tempfile\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy.stats import spearmanr, norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b537a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "AD_PATH = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/BICAN_BG_CPS.h5ad\"\n",
    "R_HOME = \"/anvil/projects/x-mcb130189/aklein/SPIDA/.pixi/envs/dist/lib/R\"\n",
    "R_SCRIPT = \"/home/x-aklein2/projects/aklein/BICAN/spida_dev/helper_scripts/sparkX.R\"\n",
    "OUTDIR = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/CPS/sparkx\"\n",
    "image_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/images/CPS/sparkx\"\n",
    "REP_KEY = \"dataset_id\"\n",
    "CELLTYPE_KEY = \"Subclass\"\n",
    "AXIS = \"MS_NORM\"\n",
    "\n",
    "min_cells = 50\n",
    "num_cores = 4\n",
    "\n",
    "COORDS_MODE = \"axis_only\"\n",
    "XY_KEYS = (\"CENTER_X\", \"CENTER_Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f7f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = Path(OUTDIR)\n",
    "image_path = Path(image_path)\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "image_path.mkdir(parents=True, exist_ok=True)\n",
    "os.environ[\"R_HOME\"] = R_HOME\n",
    "# R_BIN = subprocess.check_output([\"which\", \"Rscript\"], text=True).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dense_df(X, var_names, obs_names):\n",
    "    \"\"\"Return a dense pandas DataFrame cells×genes from AnnData.X.\"\"\"\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        arr = X.toarray()\n",
    "    elif hasattr(X, \"A\"):\n",
    "        arr = X.A\n",
    "    else:\n",
    "        arr = np.asarray(X)\n",
    "    return pd.DataFrame(arr, index=obs_names, columns=var_names)\n",
    "\n",
    "def write_rds_from_python(obj, out_path):\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame or numpy array to an .Rds file using rpy2.\n",
    "    Requires rpy2 and R in the environment.\n",
    "    \"\"\"\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    r = ro.r\n",
    "\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        with ro.conversion.localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            r_df = pandas2ri.py2rpy(obj)\n",
    "            r.assign(\".__TMP_OBJ__\", r_df)\n",
    "    else:\n",
    "            # assume numpy array\n",
    "            r.assign(\".__TMP_OBJ__\", obj)\n",
    "\n",
    "    r(f\"saveRDS(.__TMP_OBJ__, file='{str(out_path)}')\")\n",
    "\n",
    "def write_r_input(expr_df, coords_df, base_path):\n",
    "    expr_path = base_path / \"expr_df.csv\"\n",
    "    coords_path = base_path / \"coords_df.csv\"\n",
    "    expr_df.T.to_csv(expr_path)\n",
    "    coords_df.to_csv(coords_path)\n",
    "    return expr_path, coords_path\n",
    "\n",
    "\n",
    "def write_arrow_input(expr_df, coords_df, base_path: Path):\n",
    "    \"\"\"\n",
    "    Write SPARK-X inputs using Apache Arrow (Feather) format.\n",
    "    Avoids rpy2 entirely, with zero-copy I/O and fast reads in R.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    expr_df : pd.DataFrame\n",
    "        Cells × genes dataframe.\n",
    "    coords_df : pd.DataFrame\n",
    "        Cells × 2 dataframe (x/y or axis coords).\n",
    "    base_path : Path\n",
    "        Temporary directory for this replicate.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple(Path, Path)\n",
    "        Paths to expression feather and coords feather files.\n",
    "    \"\"\"\n",
    "    import pyarrow as pa\n",
    "    import pyarrow.feather as feather\n",
    "    \n",
    "    expr_path = base_path / \"expr_df.feather\"\n",
    "    coords_path = base_path / \"coords_df.feather\"\n",
    "\n",
    "    # Transpose to genes × cells for SPARK-X\n",
    "    expr_genes_cells = expr_df.T.reset_index().rename(columns={\"index\": \"gene\"})\n",
    "    coords_reset = coords_df.reset_index().rename(columns={\"index\": \"cell\"})\n",
    "\n",
    "    # Write using pyarrow Feather format (fast, compressed)\n",
    "    feather.write_feather(expr_genes_cells, expr_path)\n",
    "    feather.write_feather(coords_reset, coords_path)\n",
    "    return expr_path, coords_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da134f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sparkx_once(expr_rds, coords_rds, out_csv):\n",
    "    cmd = [\n",
    "        \"pixi\", \"run\", \"-e\", \"dist\", \n",
    "        \"Rscript\", R_SCRIPT,\n",
    "        \"--expr\", str(expr_rds),\n",
    "        \"--coords\", str(coords_rds),\n",
    "        \"--out\", str(out_csv),\n",
    "        \"--min_cells\", str(min_cells),\n",
    "        \"--num_cores\", str(num_cores),\n",
    "    ]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "def stouffer_meta(pvals, signs, weights):\n",
    "    pvals = np.clip(np.asarray(pvals, float), 1e-300, 1.0)\n",
    "    z = norm.isf(pvals / 2.0)        # two-sided to one-sided tail\n",
    "    z_signed = np.sign(signs) * z\n",
    "    Z = np.sum(weights * z_signed) / np.sqrt(np.sum(weights ** 2))\n",
    "    p = 2 * norm.sf(abs(Z))\n",
    "    return Z, p\n",
    "\n",
    "def i_squared(effects, weights):\n",
    "    k = len(effects)\n",
    "    if k <= 1:\n",
    "        return np.nan\n",
    "    mean_eff = np.average(effects, weights=weights)\n",
    "    Q = np.sum(weights * (effects - mean_eff) ** 2)\n",
    "    df = k - 1\n",
    "    return max(0.0, (Q - df) / Q) * 100 if Q > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e957ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_and_qc(per_rep_csv, fdr_thresh=0.05):\n",
    "    df = pd.read_csv(per_rep_csv)\n",
    "    if df.empty:\n",
    "        print(\"No replicate results found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    out = []\n",
    "    # group either by cell_type (if present) or do single group\n",
    "    group_cols = [\"cell_type\"] if \"cell_type\" in df.columns else []\n",
    "    group_cols_gene = group_cols + [\"gene\"]\n",
    "\n",
    "    for keys, g in df.groupby(group_cols_gene):\n",
    "        if isinstance(keys, tuple):\n",
    "            *ct_part, gene = keys\n",
    "            cell_type = ct_part[0] if ct_part else None\n",
    "        else:\n",
    "            gene = keys\n",
    "            cell_type = None\n",
    "\n",
    "        pvals = g[\"p_sparkx\"].values\n",
    "        n = g[\"n_cells\"].values\n",
    "        weights = np.sqrt(n)\n",
    "\n",
    "        # sign from Spearman rho w.r.t aligned axis\n",
    "        signs = np.sign(g[\"rho_axis\"].values)\n",
    "        Z, p_meta = stouffer_meta(pvals, signs, weights)\n",
    "        effs = signs * norm.isf(np.clip(pvals, 1e-300, 1.0) / 2.0)\n",
    "        I2 = i_squared(effs, weights)\n",
    "\n",
    "        out.append({\n",
    "            \"cell_type\": cell_type if cell_type is not None else \"ALL\",\n",
    "            \"gene\": gene,\n",
    "            \"meta_Z\": Z,\n",
    "            \"meta_p\": p_meta,\n",
    "            \"I2\": I2,\n",
    "            \"direction\": \"up\" if Z > 0 else \"down\",\n",
    "        })\n",
    "\n",
    "    meta = pd.DataFrame(out)\n",
    "    # FDR per cell type\n",
    "    meta[\"fdr\"] = meta.groupby(\"cell_type\")[\"meta_p\"].transform(\n",
    "        lambda p: multipletests(p, method=\"fdr_bh\")[1]\n",
    "    )\n",
    "    meta = meta.sort_values([\"cell_type\", \"fdr\", \"meta_p\", \"meta_Z\"])\n",
    "    meta.to_csv(OUTDIR / \"sparkx_meta_results.csv\", index=False)\n",
    "    print(f\"[meta] Saved: {OUTDIR/'sparkx_meta_results.csv'}\")\n",
    "\n",
    "    # --- Plots ---\n",
    "    # Volcano per cell type\n",
    "    for ct, g in meta.groupby(\"cell_type\"):\n",
    "        g = g.copy()\n",
    "        g[\"log10FDR\"] = -np.log10(g[\"fdr\"].clip(lower=1e-300))\n",
    "        plt.figure(figsize=(6,5))\n",
    "        sns.scatterplot(data=g, x=\"meta_Z\", y=\"log10FDR\",\n",
    "                        hue=g[\"fdr\"] < fdr_thresh,\n",
    "                        palette={True: \"crimson\", False: \"grey\"},\n",
    "                        s=18, alpha=0.7, legend=False)\n",
    "        plt.axhline(-np.log10(fdr_thresh), ls=\"--\", lw=1, c=\"black\")\n",
    "        plt.title(f\"SPARK-X Stouffer Volcano — {ct}\")\n",
    "        plt.xlabel(\"Meta Z (signed)\")\n",
    "        plt.ylabel(\"-log10(FDR)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(image_path / f\"volcano_{ct}.png\", dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    # I2 distribution\n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.histplot(data=meta, x=\"I2\", hue=\"cell_type\", bins=40,\n",
    "                 element=\"step\", fill=False)\n",
    "    plt.xlabel(\"I² (%)\")\n",
    "    plt.ylabel(\"Gene count\")\n",
    "    plt.title(\"Replicate heterogeneity (I²)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_path / \"I2_distribution.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Significant counts\n",
    "    sig = (meta[\"fdr\"] < fdr_thresh)\n",
    "    sig_counts = meta.loc[sig].groupby(\"cell_type\").size().reset_index(name=\"n_sig\")\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(data=sig_counts, x=\"cell_type\", y=\"n_sig\", color=\"steelblue\")\n",
    "    plt.ylabel(f\"# significant genes (FDR<{fdr_thresh})\")\n",
    "    plt.xlabel(\"Cell type\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Significant SVGs per cell type\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(image_path / \"sig_gene_counts.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"[plots] Saved to {image_path}\")\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f1ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_rep_csv = OUTDIR / \"sparkx_per_replicate_results.csv\"\n",
    "rows = []\n",
    "\n",
    "adata = ad.read_h5ad(AD_PATH)\n",
    "\n",
    "if REP_KEY not in adata.obs:\n",
    "    raise KeyError(f\"obs missing '{REP_KEY}'\")\n",
    "\n",
    "if CELLTYPE_KEY and CELLTYPE_KEY not in adata.obs:\n",
    "    raise KeyError(f\"obs missing '{CELLTYPE_KEY}'\")\n",
    "\n",
    "if AXIS not in adata.obs and COORDS_MODE == \"axis_only\":\n",
    "    raise KeyError(f\"obs missing '{AXIS}'\")\n",
    "\n",
    "if COORDS_MODE == \"xy\":\n",
    "    xk, yk = XY_KEYS\n",
    "    if xk not in adata.obs or yk not in adata.obs:\n",
    "        raise KeyError(f\"obs missing XY keys {XY_KEYS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896aacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group splits\n",
    "reps = adata.obs[REP_KEY].unique().tolist()\n",
    "cts = adata.obs[CELLTYPE_KEY].unique().tolist() if CELLTYPE_KEY else [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rep in reps:\n",
    "    for ct in cts:\n",
    "        idx = (adata.obs[REP_KEY] == rep)\n",
    "        label = f\"{REP_KEY}={rep}\"\n",
    "        if CELLTYPE_KEY and ct is not None:\n",
    "            idx = idx & (adata.obs[CELLTYPE_KEY] == ct)\n",
    "            label += f\", {CELLTYPE_KEY}={ct}\"\n",
    "        if COORDS_MODE == \"axis_only\": \n",
    "            idx = idx & (~adata.obs[AXIS].isna())\n",
    "\n",
    "        n_cells = int(idx.sum())\n",
    "        if n_cells < min_cells:\n",
    "            print(f\"[skip] {label} — {n_cells} cells (<{min_cells})\")\n",
    "            continue\n",
    "\n",
    "        sub = adata[idx].copy()\n",
    "        print(f\"[run] {label}: {sub.n_obs} cells, {sub.n_vars} genes\")\n",
    "\n",
    "        # Build expression: genes×cells for SPARK-X\n",
    "        expr_cells_genes = to_dense_df(sub.X, sub.var_names, sub.obs_names)  # cells×genes\n",
    "        expr_genes_cells = expr_cells_genes.T                                # genes×cells\n",
    "\n",
    "        # Build coords\n",
    "        if COORDS_MODE == \"axis_only\":\n",
    "            coords_df = pd.DataFrame({\n",
    "                \"x\": sub.obs[AXIS].values,\n",
    "                \"y\": np.zeros(sub.n_obs, dtype=float)\n",
    "            }, index=sub.obs_names)\n",
    "        else:\n",
    "            coords_df = pd.DataFrame({\n",
    "                \"x\": sub.obs[XY_KEYS[0]].values,\n",
    "                \"y\": sub.obs[XY_KEYS[1]].values\n",
    "            }, index=sub.obs_names)\n",
    "\n",
    "        # Temporary files for one run\n",
    "        with tempfile.TemporaryDirectory() as td:\n",
    "            td = Path(td)\n",
    "            out_csv    = td / \"sparkx_results.csv\"\n",
    "\n",
    "            # Should I write an handler for this choice (or is it always smarter to just use pyarrow)? \n",
    "            \n",
    "            # write RDS\n",
    "            # expr_rds   = td / \"expr_df.Rds\"\n",
    "            # coords_rds = td / \"coords_df.Rds\"\n",
    "            # write_rds_from_python(expr_genes_cells, expr_rds)\n",
    "            # write_rds_from_python(coords_df, coords_rds)\n",
    "            \n",
    "            # Write to CSV and to read in CSV's in R\n",
    "            # expr_path, coords_path = write_r_input(expr_cells_genes, coords_df, td)\n",
    "\n",
    "            # Write to pyarrow feather files in R\n",
    "            expr_path, coords_path = write_arrow_input(expr_cells_genes, coords_df, td)\n",
    "\n",
    "            print(\"Wrote CSVs files.\")\n",
    "\n",
    "            # call R\n",
    "            try:\n",
    "                run_sparkx_once(expr_path, coords_path, out_csv)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"[err] SPARK-X failed for {label}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # read results\n",
    "            if not out_csv.exists():\n",
    "                print(f\"[warn] no CSV produced for {label}\")\n",
    "                continue\n",
    "            res = pd.read_csv(out_csv)\n",
    "\n",
    "        # If empty, continue\n",
    "        if res.empty:\n",
    "            print(f\"[warn] empty results for {label}\")\n",
    "            continue\n",
    "\n",
    "        # Spearman rho (direction) for each gene vs aligned axis\n",
    "        axis_vals = sub.obs[AXIS].values if COORDS_MODE == \"axis_only\" else sub.obs[XY_KEYS[0]].values\n",
    "        # We compute rho using cells×genes table\n",
    "        rho_map = {}\n",
    "        for g in res[\"gene\"]:\n",
    "            if g not in expr_cells_genes.columns:\n",
    "                # should not happen, but be safe (filtering may drop genes)\n",
    "                continue\n",
    "            rho, _ = spearmanr(expr_cells_genes[g].values, axis_vals)\n",
    "            rho_map[g] = rho\n",
    "\n",
    "        res[\"rho_axis\"] = res[\"gene\"].map(rho_map)\n",
    "        res[\"replicate\"] = rep\n",
    "        res[\"n_cells\"] = n_cells\n",
    "        if CELLTYPE_KEY and ct is not None:\n",
    "            res[\"cell_type\"] = ct\n",
    "\n",
    "        rows.append(res)\n",
    "\n",
    "if not rows:\n",
    "    print(\"done No runs produced results.\")\n",
    "\n",
    "all_rep = pd.concat(rows, ignore_index=True)\n",
    "\n",
    "# Some SPARK versions use 'adjusted_pvalue' vs 'adjusted_pvalue' casing; keep p_sparkx consistent\n",
    "if \"adjusted_pvalue\" in all_rep.columns:\n",
    "    all_rep.rename(columns={\"adjusted_pvalue\": \"p_sparkx\"}, inplace=True)\n",
    "if \"adjusted_pValue\" in all_rep.columns:\n",
    "    all_rep.rename(columns={\"adjusted_pValue\": \"p_sparkx\"}, inplace=True)\n",
    "if \"adjusted_pval\" in all_rep.columns:\n",
    "    all_rep.rename(columns={\"adjusted_pval\": \"p_sparkx\"}, inplace=True)\n",
    "if \"adjusted_pvalue\" not in all_rep.columns and \"p_sparkx\" not in all_rep.columns:\n",
    "    # fall back to 'combined_pvalue' if adjusted missing\n",
    "    if \"combined_pvalue\" in all_rep.columns:\n",
    "        print(\"[warn] adjusted_pvalue missing; using combined_pvalue for meta (less conservative).\")\n",
    "        all_rep.rename(columns={\"combined_pvalue\": \"p_sparkx\"}, inplace=True)\n",
    "\n",
    "all_rep.to_csv(per_rep_csv, index=False)\n",
    "print(f\"[io] saved per-replicate: {per_rep_csv}\")\n",
    "\n",
    "# meta + plots\n",
    "meta_and_qc(per_rep_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dist",
   "language": "python",
   "name": "dist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
