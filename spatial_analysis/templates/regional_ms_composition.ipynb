{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ccb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "ad_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/BICAN_BG_CPS.h5ad\"\n",
    "geom_store_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/regions/region_geometries_cps.parquet\"\n",
    "N_permute = 1000\n",
    "output_path = \"/home/x-aklein2/projects/aklein/BICAN/BG/data/CPS/ms_enrichment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "from scipy.stats import norm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f4d6f",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337138ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_geometry(geometry_col):\n",
    "    \"\"\"\n",
    "    Randomly permute a GeoSeries of point geometries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geometry_col : geopandas.GeoSeries\n",
    "        A column of shapely Points (e.g., gdf.geometry).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    geopandas.GeoSeries\n",
    "        Shuffled GeoSeries (same geometries, new order).\n",
    "    \"\"\"\n",
    "    # Ensure input is a GeoSeries\n",
    "    if not isinstance(geometry_col, gpd.GeoSeries):\n",
    "        geometry_col = gpd.GeoSeries(geometry_col)\n",
    "\n",
    "    # Shuffle indices\n",
    "    shuffled = np.random.permutation(geometry_col)\n",
    "\n",
    "    return shuffled\n",
    "\n",
    "# functions from xingjiepan 2023 mouse atlas paper\n",
    "def adjust_p_value_matrix_by_BH(p_val_mtx):\n",
    "    '''Adjust the p-values in a matrix by the Benjamini/Hochberg method.\n",
    "    The matrix should be symmetric.\n",
    "    '''\n",
    "    p_val_sequential = []\n",
    "    N = p_val_mtx.shape[0]\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            p_val_sequential.append(p_val_mtx[i, j])\n",
    "\n",
    "    p_val_sequential_bh = multipletests(p_val_sequential, method='fdr_bh')[1]\n",
    "    \n",
    "    adjusted_p_val_mtx = np.zeros((N, N))\n",
    "    \n",
    "    counter = 0\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            adjusted_p_val_mtx[i, j] = p_val_sequential_bh[counter]\n",
    "            adjusted_p_val_mtx[j, i] = p_val_sequential_bh[counter]\n",
    "            counter += 1\n",
    "            \n",
    "    return adjusted_p_val_mtx\n",
    "\n",
    "def one_sided_pval(real, null_dist):\n",
    "    \"\"\"\n",
    "    Calculate one-sided p-value for real value against null distribution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    real : dict\n",
    "        Dict of cell_type to real value\n",
    "    null_dist : dict(array-like)\n",
    "        Dict of cell type to array of the null distribution values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z_scores : dict\n",
    "        Z-scores.\n",
    "    p_vals : dict\n",
    "        Raw p-values.\n",
    "    adj_p_value : dict\n",
    "        Adjusted p-values (Benjamini/Hochberg).\n",
    "    \"\"\"\n",
    "\n",
    "    z_scores = {}\n",
    "    p_vals = {}\n",
    "    for _key in real.keys(): \n",
    "        _real = real[_key]\n",
    "        _null_dist = null_dist[_key]\n",
    "        null_mean = np.mean(_null_dist)\n",
    "        null_std = np.maximum(np.std(_null_dist), 1e-6)\n",
    "        z_score = (_real - null_mean) / null_std\n",
    "        p = norm.sf(np.abs(z_score))\n",
    "        z_scores[_key] = z_score\n",
    "        p_vals[_key] = p\n",
    "\n",
    "    adj_p_value = multipletests(list(p_vals.values()), method='fdr_bh')[1]\n",
    "    return z_scores, p_vals, {_key: adj_p_value[i] for i, _key in enumerate(p_vals.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68975bba",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(output_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0467d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(ad_path)\n",
    "geoms = gpd.read_parquet(geom_store_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580adc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "donors = adata.obs['donor'].unique().tolist()\n",
    "replicates = adata.obs['replicate'].unique().tolist()\n",
    "brain_regions = ['CAH', 'CAB', 'PU', 'NAC', 'MGM1', 'SUBTH'] # adata.obs['brain_region'].unique().tolist()\n",
    "skip = [(\"UWA7648\", \"CAT\", \"ucsd\"), (\"UWA7648\", \"CAT\", \"salk\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here on this needs to be iterable. \n",
    "# contact_list = []\n",
    "pbar = tqdm(itertools.product(donors, brain_regions, replicates))\n",
    "for _i in pbar:\n",
    "    if _i in skip:\n",
    "        # print(f\"Skipping {_i}\")\n",
    "        continue\n",
    "    _donor, _brain_region, _replicate, = _i\n",
    "    pbar.set_description(f\"Processing {_donor} | {_brain_region} | {_replicate}\")\n",
    "    adata_sub = adata[ (adata.obs['donor'] == _donor) & \n",
    "                       (adata.obs['brain_region'] == _brain_region) & \n",
    "                       (adata.obs['replicate'] == _replicate) ].copy()\n",
    "    geoms_sub = geoms[ (geoms['donor'] == _donor) & \n",
    "                       (geoms['brain_region'] == _brain_region) & \n",
    "                       (geoms['lab'] == _replicate) ].copy()\n",
    "    if geoms_sub.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(adata_sub.obs, geometry=gpd.points_from_xy(adata_sub.obs['CENTER_X'], adata_sub.obs['CENTER_Y']), crs=None)\n",
    "\n",
    "    subclass_cells = gdf['Subclass'].unique().tolist()\n",
    "    group_cells = gdf['Group'].unique().tolist()\n",
    "\n",
    "    \n",
    "    # Doing GM vs. WM first, and then removing WM and doing matrix vs. striosome\n",
    "    wm_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'White_Matter'], how=\"inner\", predicate='within')\n",
    "    wm_cells = wm_cells.loc[~wm_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    sub_wm_counts = wm_cells.groupby(\"Subclass\", observed=False).size().to_dict()\n",
    "    gr_wm_counts = wm_cells.groupby(\"Group\", observed=False).size().to_dict()\n",
    "    \n",
    "    null_sub_wm_counts = {a: [] for a in subclass_cells}\n",
    "    null_gr_wm_counts = {a: [] for a in group_cells}\n",
    "    \n",
    "    for i in range(N_permute): \n",
    "        gdf.geometry = permute_geometry(gdf.geometry)\n",
    "\n",
    "        wm_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'White_Matter'], how=\"inner\", predicate='within')\n",
    "        wm_cells = wm_cells.loc[~wm_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        for a, b in wm_cells.groupby(\"Subclass\", observed=False).size().items(): \n",
    "            null_sub_wm_counts[a].append(b)\n",
    "        \n",
    "        for a, b in wm_cells.groupby(\"Group\", observed=False).size().items(): \n",
    "            null_gr_wm_counts[a].append(b)\n",
    "\n",
    "    naming = [\"subclass_white_matter\", \"group_white_matter\"]\n",
    "    real_dicts = [sub_wm_counts, gr_wm_counts]\n",
    "    null_dicts = [null_sub_wm_counts, null_gr_wm_counts]\n",
    "\n",
    "    for i, (_name, _real, _null) in enumerate(zip(naming, real_dicts, null_dicts)):\n",
    "        z_score, ps, adj_ps = one_sided_pval(_real, _null)\n",
    "        cell_types = _real.keys()\n",
    "        result_df = pd.DataFrame({\n",
    "            \"cell_type\": cell_types,\n",
    "            \"real_count\": [_real[ct] for ct in cell_types],\n",
    "            \"mean_null_count\": [np.mean(_null[ct]) for ct in cell_types],\n",
    "            \"std_null_count\": [np.std(_null[ct]) for ct in cell_types],\n",
    "            \"z_score\": [z_score[ct] for ct in cell_types],\n",
    "            \"p_value\": [ps[ct] for ct in cell_types],\n",
    "            \"adj_p_value\": [adj_ps[ct] for ct in cell_types],\n",
    "            \"log_2FC\": [np.log2( (_real[ct] + 1) / (np.mean(_null[ct]) + 1) ) for ct in cell_types]\n",
    "        })\n",
    "        \n",
    "        result_df.to_csv(Path(output_path) / f\"ms_composition_{_name}_{_donor}_{_brain_region}_{_replicate}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_regions = ['CAH', 'CAB', 'PU', 'NAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8403811",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(itertools.product(donors, brain_regions, replicates))\n",
    "for _i in pbar:\n",
    "    if _i in skip:\n",
    "        # print(f\"Skipping {_i}\")\n",
    "        continue\n",
    "    _donor, _brain_region, _replicate, = _i\n",
    "    pbar.set_description(f\"Processing {_donor} | {_brain_region} | {_replicate}\")\n",
    "    adata_sub = adata[ (adata.obs['donor'] == _donor) & \n",
    "                       (adata.obs['brain_region'] == _brain_region) & \n",
    "                       (adata.obs['replicate'] == _replicate) ].copy()\n",
    "    geoms_sub = geoms[ (geoms['donor'] == _donor) & \n",
    "                       (geoms['brain_region'] == _brain_region) & \n",
    "                       (geoms['lab'] == _replicate) ].copy()\n",
    "    if geoms_sub.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    gdf = gpd.GeoDataFrame(adata_sub.obs, geometry=gpd.points_from_xy(adata_sub.obs['CENTER_X'], adata_sub.obs['CENTER_Y']), crs=None)\n",
    "    # break\n",
    "    # Removing all WM cells from this part of the analysis:\n",
    "    wm_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'White_Matter'], how=\"inner\", predicate='within')\n",
    "    wm_cells = wm_cells.loc[~wm_cells.index.duplicated(keep=\"first\")]\n",
    "    gdf = gdf.drop(index=wm_cells.index).copy()\n",
    "    gdf['Subclass'] = gdf['Subclass'].cat.remove_unused_categories()\n",
    "    gdf['Group'] = gdf['Group'].cat.remove_unused_categories()\n",
    "\n",
    "    subclass_cells = gdf['Subclass'].unique().tolist()\n",
    "    group_cells = gdf['Group'].unique().tolist()\n",
    "    \n",
    "    mat_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Matrix'], how=\"inner\", predicate='within')\n",
    "    mat_cells = mat_cells.loc[~mat_cells.index.duplicated(keep=\"first\")]\n",
    "    str_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Striosome'], how=\"inner\", predicate='within')\n",
    "    str_cells = str_cells.loc[~str_cells.index.duplicated(keep=\"first\")]\n",
    "    \n",
    "    sub_mat_counts = mat_cells.groupby(\"Subclass\", observed=False).size().to_dict()\n",
    "    sub_str_counts = str_cells.groupby(\"Subclass\", observed=False).size().to_dict()\n",
    "    \n",
    "    gr_mat_counts = mat_cells.groupby(\"Group\", observed=False).size().to_dict()\n",
    "    gr_str_counts = str_cells.groupby(\"Group\", observed=False).size().to_dict()    \n",
    "\n",
    "    null_sub_mat_counts = {a: [] for a in subclass_cells}\n",
    "    null_sub_str_counts = {a: [] for a in subclass_cells}\n",
    "    \n",
    "    null_gr_mat_counts = {a: [] for a in group_cells}\n",
    "    null_gr_str_counts = {a: [] for a in group_cells}\n",
    "\n",
    "    for i in range(N_permute): \n",
    "        gdf.geometry = permute_geometry(gdf.geometry)\n",
    "\n",
    "        mat_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Matrix'], how=\"inner\", predicate='within')\n",
    "        mat_cells = mat_cells.loc[~mat_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        str_cells = gpd.sjoin(gdf, geoms[geoms['type'] == 'Striosome'], how=\"inner\", predicate='within')\n",
    "        str_cells = str_cells.loc[~str_cells.index.duplicated(keep=\"first\")]\n",
    "\n",
    "        for a, b in mat_cells.groupby(\"Subclass\", observed=False).size().items(): \n",
    "            null_sub_mat_counts[a].append(b)\n",
    "        \n",
    "        for a, b in str_cells.groupby(\"Subclass\", observed=False).size().items(): \n",
    "            null_sub_str_counts[a].append(b)\n",
    "\n",
    "        for a, b in mat_cells.groupby(\"Group\", observed=False).size().items(): \n",
    "            null_gr_mat_counts[a].append(b)\n",
    "        \n",
    "        for a, b in str_cells.groupby(\"Group\", observed=False).size().items(): \n",
    "            null_gr_str_counts[a].append(b)\n",
    "\n",
    "    naming = [\"subclass_matrix\", \"subclass_striosome\", \"group_matrix\", \"group_striosome\",]\n",
    "    real_dicts = [sub_mat_counts, sub_str_counts, gr_mat_counts, gr_str_counts]\n",
    "    null_dicts = [null_sub_mat_counts, null_sub_str_counts, null_gr_mat_counts, null_gr_str_counts]\n",
    "\n",
    "    for i, (_name, _real, _null) in enumerate(zip(naming, real_dicts, null_dicts)):\n",
    "        z_score, ps, adj_ps = one_sided_pval(_real, _null)\n",
    "        cell_types = _real.keys()\n",
    "        result_df = pd.DataFrame({\n",
    "            \"cell_type\": cell_types,\n",
    "            \"real_count\": [_real[ct] for ct in cell_types],\n",
    "            \"mean_null_count\": [np.mean(_null[ct]) for ct in cell_types],\n",
    "            \"std_null_count\": [np.std(_null[ct]) for ct in cell_types],\n",
    "            \"z_score\": [z_score[ct] for ct in cell_types],\n",
    "            \"p_value\": [ps[ct] for ct in cell_types],\n",
    "            \"adj_p_value\": [adj_ps[ct] for ct in cell_types],\n",
    "            \"log_2FC\": [np.log2( (_real[ct] + 1) / (np.mean(_null[ct]) + 1) ) for ct in cell_types]\n",
    "        })\n",
    "        \n",
    "        result_df.to_csv(Path(output_path) / f\"ms_composition_{_name}_{_donor}_{_brain_region}_{_replicate}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessing",
   "language": "python",
   "name": "preprocessing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
